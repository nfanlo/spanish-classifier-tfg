{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-05 10:06:16.633579: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#Modelo distilBERT\n",
    "#Libreria transformers (modelo BERT predefinido para la clasificación (BertForSequenceClassification))\n",
    "#Libreria sera BERT + Capa de clasificación por encima\n",
    "#Debemos tokenizar nuestro dataset (tokens + attention mask + max_length)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "from keras.models import Model\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "MAX_LEN = 38\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Environment stopwords for train\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_train['review']=df_train['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment stopwords for dev\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_dev['review']=df_dev['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 34\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True,)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-multilingual-cased', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGwCAYAAABb6kfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBXUlEQVR4nO3deVxU5f4H8M+ZgZkB2UFAFlFEUTJBUblUbveSWt3UrLSyJFyqq7SRlt5+ampGN8vM8mppaptpt9LSyjIMl9QWFcsNNxRcQJB9n5lzfn+Qo5NDzjAzjDPn8369zuveOTzPOd8Jh+88y3keQZIkCUREROQSFI4OgIiIiGyHiZ2IiMiFMLETERG5ECZ2IiIiF8LETkRE5EKY2ImIiFwIEzsREZELcXN0ANYQRRHnzp2Dt7c3BEFwdDhERGQhSZJQVVWFsLAwKBT2a2vW19ejsbHR6uuoVCpoNBobRGQ/Tp3Yz507h8jISEeHQUREViooKEBERIRdrl1fX4+OUV4ovKC3+lqhoaHIy8u7rpO7Uyd2b29vAMDpvR3g48VRBVfX9+0Jjg6BWlH4az85OgRqBTposQNfG/6e20NjYyMKL+hxek8H+Hi3PFdUVomISjyFxsZGJnZ7udT97uOlsOqXRc5Bqb5+P0hke26Cu6NDoNbwx6LmrTGc6uUtwMu75fcR4RxDvk6d2ImIiMyll0TordgdRS+JtgvGjpjYiYhIFkRIENHyzG5N3dbE/msiIiIXwhY7ERHJgggR1nSmW1e79TCxExGRLOglCXqp5d3p1tRtTeyKJyIiciFssRMRkSzIZfIcEzsREcmCCAl6GSR2dsUTERG5ELbYiYhIFtgVT0RE5EI4K56IiIicDlvsREQkC+IfhzX1nQETOxERyYLeylnx1tRtTUzsREQkC3oJVu7uZrtY7Ilj7ERERC6ELXYiIpIFjrETERG5EBEC9BCsqu8M2BVPRETkQthiJyIiWRClpsOa+s6AiZ2IiGRBb2VXvDV1WxO74omIiFwIW+xERCQLcmmxM7ETEZEsiJIAUbJiVrwVdVsTu+KJiIhcCFvsREQkC+yKJyIiciF6KKC3oqNab8NY7ImJnYiIZEGycoxd4hg7ERERtTa22ImISBY4xk5ERORC9JICesmKMXYnWVKWXfFEREQuhC12IiKSBRECRCvasyKco8nOxE5ERLIglzF2dsUTERG5ELbYiYhIFqyfPMeueCIioutG0xi7FZvAsCueiIiIWhtb7EREJAuilWvFc1Y8ERHRdYRj7ERERC5EhEIWz7FzjJ2IiMiFsMVORESyoJcE6K3YetWauq2JiZ2IiGRBb+XkOT274omIiKi1scVORESyIEoKiFbMihc5K56IiOj6wa54IiIicjpssRMRkSyIsG5mu2i7UOyKiZ2IiGTB+gVqnKOT2zmiJCIiIrOwxU5ERLJg/VrxztEWZmInIiJZkMt+7EzsREQkC2yxk0N9uTIIny4JRmmxG6Lj6jDpxbPo2rO22fLVFUqsejkUP37jh6pyJYIjGvHY7LPo+4+qVoyaWuL+Gw8grVcOgjxrkVsSiJe23YLfi0JMlk3pdBITE/eivV8F3BQi8st9sWpfPDbkxrZy1PRndz5cgnv+dQEBbXU4ecgD//2/cOTmeDZbvt8/y5H6bCFCIhpxNk+Nd+e1wy9bfAw/9wvSYvzz55E4oAptfPU4sNsLi/8vHOfy1IYy/m21mDDjPHr1r4Knl4iCE2qseSMYO772s+dbpevcdfH1Y/HixejQoQM0Gg2SkpLw888/Ozokh8r+wg/vzA7DmIxCLP42F9FxdXj+gWiUl5j+HqZtFDD9vk4oOqPC/71zCsu3H8FT8wsQGKpt5cjJUkM7H8ez/X7Ef3/ujXvX3IPckkC8PWwjAjxMf4mrqFfjnV97Ycz/RmLk6lFYd7grXkz5ATe3z2/lyOlKA4aV4ZFZ5/DRglBMHtIFJw9pMG/1SfgGmv4MxvWuwfT/nsamjwMwaXAX7Nzkg1krTiEqtu6PEhJmrTiFdlGNeCGtIyYP7oKiM+54ee0JqD30hutMXZSPyE71eOHhjnj0713w49e++Pfbp9Gpe/ONADm7tECNNYczcHiUa9euRUZGBmbNmoW9e/ciPj4eQ4YMwYULFxwdmsN8/k5bDH3gIobcV4qoLg144j9noPYQ8e3HASbLf7smAFXlSsxakYcb+tYgNLIRPZJr0OmG+laOnCyVmrAfnx6Mw/rDXXGiLACzfxiAep07RsYdMVn+l7PhyDoZjZNl/iio9MWH+3vgaEkgerUrbOXI6UojHynBptUB+G5tAPKPabDouQg01AkYcn+pyfIjJhTj1x+88emSYBQc1+D9+e1w/HcPDE+7CAAIj25EXO9avDktAkf3e+LMCQ3enBYBtUbCoLvKDdeJ612LL1YEITfHE4X5anz8RghqKpTo3KPO5H3lTpQEqw9n4PDEvmDBAkycOBFpaWmIi4vD0qVL4enpiRUrVjg6NIfQNgo49psnevWrNpxTKICe/apxaE8bk3V2f+eLbok1eOvfERjd4wY8MigWHy8Khl5vsjhdJ9wVesQFF2NXQYThnAQBuwvCER9aZMYVJCRFnEEH/3L8eq6d/QKlv+TmLqJzj1rs3e5tOCdJAvZt90ZcoumWc7fEWuy7ojwA7NnqjW6JNQAAd1XTUiiNDZcTiSQJ0DYKuKFPjeHcoV89MWBYObz9dBAECQOGl0GlkfDbTi+bvT9yPg4dY29sbMSePXswffp0wzmFQoGUlBTs2rXrqvINDQ1oaGgwvK6srGyVOFtTZakSol6AX1vjLjz/IC0KjqtN1jl/WoWcH73w97vK8OKHJ3E2T423/h0BvVbAg8+YkyDIEfw86uGmkHCx1sPo/MVaT3T0L2+2npeqAT+kvQ93pQhREjA3ux92FUTaOVpqjk+AHko3oLzY+M9pWYkbImMaTNbxb6tD2Z+G1sqK3eAfrAMAFBzXoOiMO8ZNP483notAfa0CIx8pQdswLQJCLv9tmPdoB/x76Sl8euggdFqgoU6B2eM74Nwp038r5E60sjvdWRaocWhiLykpgV6vR0iI8UShkJAQHDlydVdkZmYmZs+e3VrhOQ1JAvwCdXhyfgGUSqBzjzpcLHTHp0uCmdhdUE2jCnevGQVPdy2SIs/g2X47cabSB7+cDXd0aGQjep2AOeM7IGNBAT47fBB6HbBvuzd+zvKGcEVvcOqz5+HlI+K5UdGoLHVD8tAKPL/0FJ65Kwanjng0fwOZsn53NyZ2m5s+fToyMjIMrysrKxEZ6VotFZ8APRRKCeXF7kbny0rc4d9WZ7JOQLAOSjcJSuXlc+0716P0gju0jQLcVc6xI5HclNdpoBMFBHoaj4cGetaipLb52dQSBORX+AIAjpQEIdq/DBMT9zGxO0hlqRJ6HeD3p8+nf5AOZcWm/8SWFbvBP+hP5dvqUHbhcvnjv3ti0q2x8PTWw91dQkWpG97YeAxHf2tK2O2iGjB83EU8MjAWp49qAAAnD3ngxqQaDHv4IhZNiwDJk0O/fgQFBUGpVKKoyLhVWVRUhNDQ0KvKq9Vq+Pj4GB2uxl0loXOPWuzbcXmMTBSBnB1eiEusMVknrk8Nzp9SQ7xih4IzJ9UICNEyqV/HtKIShy60xd8izhjOCZCQFHkW+wtNP+5mikIA3JWcUOEoOq0Cx37zRM9bLj9aKggSEm6pxqE9pr+gHd7jiYQr5tEAQK/+VThsYh5NbZUSFaVuCOvYgM7xtdj1bdOXOrVH0wde/NPOJHo9ICj4uTdFD8Hqwxk4NLGrVCokJiYiKyvLcE4URWRlZSE5OdmBkTnWyEeK8c3qQGz+xB/5x9R4c1rTGNvg+5pm2L7yRHuseOnyZKl/ji1BVbkSS2aE48wJNX763gdrFoXgzodLHPUWyEzv5cTjnhsOY3jXI4j2L8PMQdvg4abFukNdAQAv3ZqFp5J3G8pPSNyL5MgCRPhUItq/DKk9c3Bn7FFszO3sqLdAAD5/Jwi3PVCKlHtLERlTj8dfPgONp4jv1jQ9yTL1jXykTT9vKL9+eVv0HliJux+9gMiYejz4TCE696jDFysDDWX6/bMcPZKrEdq+AclDKpC55gR2bfLF3q1Nk+4Kjmtw9qQKT75yBrEJtWgX1YC7H72AXv2rsXOTb+v+B3ASl7rirTmcgcO74jMyMpCamorevXujb9++WLhwIWpqapCWlubo0Bxm4PByVFx0w/vz26Gs2A3RN9Rh3kcnDV3xxWdVUFzx7ys4XIt5q0/g7RfC8VhKLIJCtRgxoRijJsv3kUFnselYDAI86pCe9AuC2tTiSHEQHv3yn7hY19TSa+dVDemKR2w83bWYMXA7Qryq0aBzw8kyP0zb/A9sOhbjqLdAALZ+6Q/fQD3GTi2Ef1sdTh70wPNjOqK8pGlIrW14o1HL+tCvbfDy5CikPleIh6cV4lyeGrPHdcDp3Mvj4gEhWjz6wjn4BelQesEN3//PH6sXXu7J0esE/N9D0Rj/7/OY/V4ePNqIOJenwqtPRhotdEPyI0iS5PA+m7feegvz589HYWEhEhISsGjRIiQlJV2zXmVlJXx9fVF2NBo+3s7xTYpa7oY3Jzk6BGpFEZk7HR0CtQKdpEU2vkBFRYXdhlcv5YqZP6VA4+V+7QrNqK/WYk7S93aN1RYc3mIHgPT0dKSnpzs6DCIicmGcFU9ERORC5LIJjHNESURE5KQs2Q9l1apVEATB6NBoNBbdj4mdiIhkQfpjP/aWHlILHndryX4oPj4+OH/+vOE4ffq0RfdkYiciIlm41BVvzQE0Tca78rhyqfM/a8l+KIIgIDQ01HD8eXXWa2FiJyIiskBkZCR8fX0NR2Zmpslyl/ZDSUlJMZz7q/1QLqmurkZUVBQiIyMxfPhwHDx40KL4OHmOiIhkwdqtVy/VLSgoMHrcTa02vemOpfuhAEBsbCxWrFiBHj16oKKiAq+++ipuuukmHDx4EBER5i0TzMRORESyoLdyd7dLde25pHlycrLRyqs33XQTunXrhrfffhtz58416xrsiiciIrIDS/dDMcXd3R09e/bE8ePHzb4vEzsREcnCpa54aw5L2GI/FL1ej99//x3t2rW7duE/sCueiIhkQYQCohXt2ZbUvdZ+KGPHjkV4eLhhAt6cOXPwt7/9DTExMSgvL8f8+fNx+vRpTJgwwex7MrETERHZyejRo1FcXIyZM2ca9kPZtGmTYUJdfn4+FFfs6lVWVoaJEyeisLAQ/v7+SExMxM6dOxEXF2f2PZnYiYhIFvSSAL0Vs+JbWvev9kPJzs42ev3666/j9ddfb9F9LmFiJyIiWbDV427XOyZ2IiKSBcnK3d0kbgJDRERErY0tdiIikgU9BOhbsJHLlfWdARM7ERHJgihZN04uSjYMxo7YFU9ERORC2GInIiJZEK2cPGdN3dbExE5ERLIgQoBoxTi5NXVbk3N8/SAiIiKzsMVORESy4KiV51obEzsREcmCXMbYnSNKIiIiMgtb7EREJAsirFwr3kkmzzGxExGRLEhWzoqXmNiJiIiuH3LZ3Y1j7ERERC6ELXYiIpIFucyKZ2InIiJZYFc8EREROR222ImISBbkslY8EzsREckCu+KJiIjI6bDFTkREsiCXFjsTOxERyYJcEju74omIiFwIW+xERCQLcmmxM7ETEZEsSLDukTXJdqHYFRM7ERHJglxa7BxjJyIiciFssRMRkSzIpcXOxE5ERLIgl8TOrngiIiIXwhY7ERHJglxa7EzsREQkC5IkQLIiOVtTtzWxK56IiMiFsMVORESywP3YiYiIXIhcxtjZFU9ERORC2GInIiJZkMvkOSZ2IiKSBbl0xTOxExGRLMilxc4xdiIiIhfiEi32xA/GQ6HRODoMsrNuQ084OgRqReX7+zg6BGoFOm098N0XrXIvycqueGdpsbtEYiciIroWCYAkWVffGbArnoiIyIWwxU5ERLIgQoDAleeIiIhcA2fFExERkdNhi52IiGRBlAQIXKCGiIjINUiSlbPinWRaPLviiYiIXAhb7EREJAtymTzHxE5ERLLAxE5ERORC5DJ5jmPsRERELoQtdiIikgW5zIpnYiciIlloSuzWjLHbMBg7Ylc8ERGRC2GLnYiIZIGz4omIiFyIBOv2VHeSnnh2xRMREbkSttiJiEgW2BVPRETkSmTSF8+ueCIikoc/WuwtPdDCFvvixYvRoUMHaDQaJCUl4eeffzar3po1ayAIAkaMGGHR/ZjYiYiI7GTt2rXIyMjArFmzsHfvXsTHx2PIkCG4cOHCX9Y7deoUpkyZgn79+ll8TyZ2IiKShUsrz1lzAEBlZaXR0dDQ0Ow9FyxYgIkTJyItLQ1xcXFYunQpPD09sWLFimbr6PV6jBkzBrNnz0Z0dLTF75OJnYiIZMGabvgrJ95FRkbC19fXcGRmZpq8X2NjI/bs2YOUlBTDOYVCgZSUFOzatavZOOfMmYPg4GCMHz++Re+Tk+eIiIgsUFBQAB8fH8NrtVptslxJSQn0ej1CQkKMzoeEhODIkSMm6+zYsQPvvvsucnJyWhwfEzsREcmDFRPgDPUB+Pj4GCV2W6mqqsJDDz2EZcuWISgoqMXXYWInIiJZaO3d3YKCgqBUKlFUVGR0vqioCKGhoVeVP3HiBE6dOoU777zTcE4URQCAm5sbcnNz0alTp2vel2PsREREdqBSqZCYmIisrCzDOVEUkZWVheTk5KvKd+3aFb///jtycnIMx7BhwzBo0CDk5OQgMjLSrPuyxU5ERPLggAVqMjIykJqait69e6Nv375YuHAhampqkJaWBgAYO3YswsPDkZmZCY1Gg+7duxvV9/PzA4Crzv8VJnYiIpIFRywpO3r0aBQXF2PmzJkoLCxEQkICNm3aZJhQl5+fD4XCtp3nZiX2L7/80uwLDhs2rMXBEBERuZr09HSkp6eb/Fl2dvZf1l21apXF9zMrsZu7nJ0gCNDr9RYHQURE1CqcZL13a5iV2C/NyiMiInJWctndzaqO/fr6elvFQUREZF+SDQ4nYHFi1+v1mDt3LsLDw+Hl5YWTJ08CAGbMmIF3333X5gESERGR+SxO7PPmzcOqVavwyiuvQKVSGc53794dy5cvt2lwREREtiPY4Lj+WZzY33//fbzzzjsYM2YMlEql4Xx8fHyza98SERE5HLviTTt79ixiYmKuOi+KIrRarU2CIiIiopaxOLHHxcVh+/btV53/9NNP0bNnT5sERUREZHMyabFbvPLczJkzkZqairNnz0IURXz++efIzc3F+++/j40bN9ojRiIiIuvZaHe3653FLfbhw4djw4YN+P7779GmTRvMnDkThw8fxoYNG3DrrbfaI0YiIiIyU4vWiu/Xrx82b95s61iIiIjsprW3bXWUFm8C8+uvv+Lw4cMAmsbdExMTbRYUERGRzTlgdzdHsDixnzlzBvfffz9+/PFHw3Zy5eXluOmmm7BmzRpERETYOkYiIiIyk8Vj7BMmTIBWq8Xhw4dRWlqK0tJSHD58GKIoYsKECfaIkYiIyHqXJs9ZczgBi1vsW7duxc6dOxEbG2s4FxsbizfffBP9+vWzaXBERES2IkhNhzX1nYHFiT0yMtLkQjR6vR5hYWE2CYqIiMjmZDLGbnFX/Pz58/H444/j119/NZz79ddf8eSTT+LVV1+1aXBERERkGbNa7P7+/hCEy2MLNTU1SEpKgptbU3WdTgc3NzeMGzcOI0aMsEugREREVpHJAjVmJfaFCxfaOQwiIiI7k0lXvFmJPTU11d5xEBERkQ20eIEaAKivr0djY6PROR8fH6sCIiIisguZtNgtnjxXU1OD9PR0BAcHo02bNvD39zc6iIiIrksy2d3N4sT+7LPPYsuWLViyZAnUajWWL1+O2bNnIywsDO+//749YiQiIiIzWdwVv2HDBrz//vsYOHAg0tLS0K9fP8TExCAqKgofffQRxowZY484iYiIrCOTWfEWt9hLS0sRHR0NoGk8vbS0FABwyy23YNu2bbaNjoiIyEYurTxnzeEMLG6xR0dHIy8vD+3bt0fXrl3xySefoG/fvtiwYYNhUxiyzAPdDmB89xy09ajDkbJAzN11M34vCTFZ9taok3gsfh/ae1fATSHidKUvVh6IxxcnuhjKpPf8BXd0PIHQNtXQigocvNgWr+/pi9+KTV+TWo9uXS10a2oglYoQOrlB9aQPFN3cr10vqx7aORVQ3KKGep6f0c/EUzpo366CuF8L6CUIUW5QzfWDIkRpp3dB5hox6BDuG/IbAnzrcLwgAIs+TsaRvGCTZe/odwRDko+hY3gZAODo6SAsW9fbqHy/XnkYNuAIukSVwNerARNm34XjBYGt8l7IeVjcYk9LS8P+/fsBANOmTcPixYuh0Wjw9NNPY+rUqRZda9u2bbjzzjsRFhYGQRCwfv16S8Nxerd1PI7pfXdicU5v3PXl3ThSGoh3h3yFAE2dyfIVDWos2d8LozfehWHr78Xnx2LxUr8fcEt4gaHMqQo/zNl9C+5cPwoPfDUCZ6u8sWLIV/Bv5prUOnRb6qFdXAW3VC+olwVC0ckdDVPKIJWJf1lPPK+HdkkVFD2u/gIgntWh4fFSKNq7Qb3QH+oVgXBPbQNB5Rxdhq5sUJ8TmDRqN1Zt6IWJc0bgREEA5j+1CX7epj+HCbHnkfVzJzz96h2YnDkMF8ra4NWnNyHIr8ZQRqPS4fdjIXjnsz6t9TZci0wmz1ncYn/66acN/z8lJQVHjhzBnj17EBMTgx49elh0rZqaGsTHx2PcuHEYOXKkpaG4hLTuv+GT3G74/FhXAMCsH/tjYMRp3N3lCJb91vOq8j8Xhhu9fv9QD4yIOYrEkPPYcTYSALDxZGejMpk/34R7Y48g1v8idp/ntrqOovukBsp/esDtdg8AgPsz3tDvboDu6zq4j2ljso6kl6B9sQLuaV4Qf2uEVG38l0W3vBrKJDXc/+V9+WS4VU+xko3ce+sBfLW9Kzb92NSbtuDDW/C3HgW4/ZajWP1N/FXl5y0fZPR6/qp+6N/rFHp1O4fvdjV9pjfvbvrf0MAqO0dPzszqvwBRUVGIiopqUd3bbrsNt912m7UhOC13hR43BBbj7f2XE7gEATvPRaBn2yIzriDhb+3OoqNvOV79NanZe4yOPYTKBhVyS9ll5yiSVoJ0VAflFQlcUAhQJqogHrx6U6VLdO/VAH4KuN3hgcbfjNeMkEQJ+l2NcLvfEw1TyiAe00Jop4T7mDZQ9tPY7b3Qtbkp9YiNKsHqry8ncEkSsOdwOOKizflsA2qVDm5KEVU1anuFKTsCrNzdzWaR2JdZiX3RokVmX/CJJ55ocTDX0tDQgIaGBsPryspKu92rNfir6+GmkHCxzsPo/MU6D0T7lTdbz8u9Advu+wAqpQhRFDB7Vz/sPBdpVGZg5GksGLgZHm46FNd6Yty3/0RZg0czVyS7qxABPQB/49EvwV8BMb/RZBX9b43QfV0HzfJmvpCViUCdBN3qGriP94L7o17Q/9yIxhkVUC1UQJmgsvGbIHP5etVDqZRQWmn8mSur1KB9aLlZ13j0nl9QUu6JPYe4ayZZxqzE/vrrr5t1MUEQ7JrYMzMzMXv2bLtd31nUaFUYsf5eeLprkRx2FtP67kRBlbdRN/1P58MwYv298NfUY1TsYSwctBn3bhiJ0nomd2cg1YrQzquAaooPBL9mpsL80fJQ3qyB26imngBFZ3eIBxqh/6KWid2JPXDbfvy970k8Nf92NOo4tGIzMnnczax/MXl5efaOwyzTp09HRkaG4XVlZSUiIyP/osb1raxBA50oINDDeDJNoEcdSmo9m60nQUB+lS8A4EhpEDr5luGRHvuMEnudzh35Vb7Ir/LF/uIQfHv3atzT5TDe+a2Xfd4M/TVfBaBEUyv7ClKZCCHg6tnr0lk9pEIRjf8uv3zyj6p1fy+C+oNACMFKQAkIHYzrK6LcIP7efPc+2V9FtQZ6vYAAH+PPtr9PPUor/vrL9ejBv+GB2/bjmdduw8kzHD6zKS4pe/1Rq9Xw8fExOpyZVlTi4MW2SA47azgnQEJy2Fnss+DRNIUgQaXUX6MMrlmG7EdwFyB0cYN+z+Vud0mUoN/bCMUNV892F9q7Qb0yEOrllw/FzWooeqqgXt6U1AV3AYqu7pDyjX+vYoEeAh91cyidXonc00Ho1e2c4ZwgSEjsehaHTjb/2b5v6H489M99eHbhUOSebtsaoZILYh+Pg6080AP/6fcDDpS0xW/FwUi94Td4uGnx+dFYAMB/+m9BUU0bLNjTNDnukR57caCkLfKrfKFS6DEgMh/DYo7hhZ39AAAeblo8Fr8XW/I7oLjWE/6aeozpdgAhnjXYlNfJYe+TALdRbaDNrICuqzsUXd2h+7QWqJPgdlvTRLfGeRUQ2irg/og3BLUAIdr44yl4CZAAKK4473afJxpnV0AX7w5FTxXEnxsh7mqAaiH3bXC0/23ujunjtiH3dBAO57XFPSkHoVHr8M2PTTPbp4/LRkl5Gyz7vOnRtfuH7kfa8D14cdkgFJZ4IcCnFgBQ1+COuoamL3/ebeoRElCDQL+mn0X+MV5fWuGB0srme/noDzJpsTs0sVdXV+P48eOG13l5ecjJyUFAQADat2/vwMhazzd5MQjQ1OOJXr+grUctDpcGYcJ3d+BifdOHtF2bKohX/GPydNNhVvJ2hLapQb3eDSfL/TB169/xTV4MAEAvCYj2Lcddf/8W/pp6lDdo8HtxMMZ8PRzHywMc8RbpD25/1wDlInQrqpsWqIlxg3q+v6ErXrqgt7gPTdlfA/cMCbqPaiAtqoLQ3g2qOb5Q9uD4uqP98Esn+HnVI234XgT41OJ4QSCeXTgUZX8k4JDAakhXjNkOH3gYKncRcyZlGV1n1Zc9serLRADAzfH5mDbu8gqfsx794aoy1DxrV49zlpXnBEmSHBZqdnY2Bg0adNX51NRUrFq16pr1Kysr4evri+gZ86DQ8PEeV9et30lHh0CtqPw/8vhyL3c6bT12fTcLFRUVdhtevZQrOsyzLleI9fU49fzzdo3VFhzaYh84cCAc+L2CiIjkRCZd8S2aPLd9+3Y8+OCDSE5OxtmzTRO/PvjgA+zYscOmwREREdmMTJaUtTixf/bZZxgyZAg8PDywb98+w4IxFRUVeOmll2weIBEREZnP4sT+4osvYunSpVi2bBnc3S8/pnPzzTdj7969Ng2OiIjIVrhtazNyc3PRv3//q877+vqivLzcFjERERHZnkxWnrO4xR4aGmr0iNolO3bsQHR0tE2CIiIisjmOsZs2ceJEPPnkk/jpp58gCALOnTuHjz76CFOmTMG//vUve8RIREREZrK4K37atGkQRRH/+Mc/UFtbi/79+0OtVmPKlCl4/PHH7REjERGR1eSyQI3FiV0QBDz//POYOnUqjh8/jurqasTFxcHLy8se8REREdmGTJ5jb/ECNSqVCnFxcbaMhYiIiKxkcWIfNGgQBKH5mYFbtmyxKiAiIiK7sPaRNVdtsSckJBi91mq1yMnJwYEDB5CammqruIiIiGyLXfGmvf766ybPv/DCC6iurrY6ICIiImq5Fq0Vb8qDDz6IFStW2OpyREREtiWT59httrvbrl27oOHWqUREdJ3i427NGDlypNFrSZJw/vx5/Prrr5gxY4bNAiMiIiLLWZzYfX19jV4rFArExsZizpw5GDx4sM0CIyIiIstZlNj1ej3S0tJw4403wt/f314xERER2Z5MZsVbNHlOqVRi8ODB3MWNiIicjly2bbV4Vnz37t1x8uRJe8RCREREVrI4sb/44ouYMmUKNm7ciPPnz6OystLoICIium65+KNugAVj7HPmzMEzzzyD22+/HQAwbNgwo6VlJUmCIAjQ6/W2j5KIiMhaMhljNzuxz549G4899hh++OEHe8ZDREREVjA7sUtS01eVAQMG2C0YIiIie+ECNSb81a5uRERE1zV2xV+tS5cu10zupaWlVgVERERELWdRYp89e/ZVK88RERE5A0d1xS9evBjz589HYWEh4uPj8eabb6Jv374my37++ed46aWXcPz4cWi1WnTu3BnPPPMMHnroIbPvZ1Fiv++++xAcHGxJFSIiouuDA7ri165di4yMDCxduhRJSUlYuHAhhgwZgtzcXJP5NCAgAM8//zy6du0KlUqFjRs3Ii0tDcHBwRgyZIhZ9zT7OXaOrxMREVlmwYIFmDhxItLS0hAXF4elS5fC09Oz2W3OBw4ciLvuugvdunVDp06d8OSTT6JHjx7YsWOH2fc0O7FfmhVPRETklGy0H/ufF2ZraGgwebvGxkbs2bMHKSkphnMKhQIpKSnYtWvXtcOVJGRlZSE3Nxf9+/c3+22andhFUWQ3PBEROS1brRUfGRkJX19fw5GZmWnyfiUlJdDr9QgJCTE6HxISgsLCwmbjrKiogJeXF1QqFe644w68+eabuPXWW81+nxZv20pEROSUbDTGXlBQAB8fH8NptVptVVh/5u3tjZycHFRXVyMrKwsZGRmIjo7GwIEDzarPxE5ERGQBHx8fo8TenKCgICiVShQVFRmdLyoqQmhoaLP1FAoFYmJiAAAJCQk4fPgwMjMzzU7sFm8CQ0RE5JRsNMZuLpVKhcTERGRlZRnOiaKIrKwsJCcnm30dURSbHcc3hS12IiKSBUc8x56RkYHU1FT07t0bffv2xcKFC1FTU4O0tDQAwNixYxEeHm4Yp8/MzETv3r3RqVMnNDQ04Ouvv8YHH3yAJUuWmH1PJnYiIiI7GT16NIqLizFz5kwUFhYiISEBmzZtMkyoy8/Ph0JxufO8pqYGkyZNwpkzZ+Dh4YGuXbviww8/xOjRo82+JxM7ERHJg4PWik9PT0d6errJn2VnZxu9fvHFF/Hiiy+27EZ/YGInIiJZkMvubpw8R0RE5ELYYiciInngtq1EREQuRCaJnV3xRERELoQtdiIikgXhj8Oa+s6AiZ2IiORBJl3xTOxERCQLfNyNiIiInA5b7EREJA/siiciInIxTpKcrcGueCIiIhfCFjsREcmCXCbPMbETEZE8yGSMnV3xRERELoQtdiIikgV2xRMREbkSdsUTERGRs3GJFnuHz8rhplQ7OgyysxPlnRwdArWilxetcHQI1Apqq/TY9V3r3Itd8URERK5EJl3xTOxERCQPMknsHGMnIiJyIWyxExGRLHCMnYiIyJWwK56IiIicDVvsREQkC4IkQZBa3uy2pm5rYmInIiJ5YFc8ERERORu22ImISBY4K56IiMiVsCueiIiInA1b7EREJAvsiiciInIlMumKZ2InIiJZkEuLnWPsRERELoQtdiIikgd2xRMREbkWZ+lOtwa74omIiFwIW+xERCQPktR0WFPfCTCxExGRLHBWPBERETkdttiJiEgeOCueiIjIdQhi02FNfWfArngiIiIXwhY7ERHJA7viiYiIXIdcZsUzsRMRkTzI5Dl2jrETERG5ELbYiYhIFtgVT0RE5EpkMnmOXfFEREQuhC12IiKSBXbFExERuRLOiiciIiJnwxY7ERHJArviiYiIXAlnxRMREZGzYYudiIhkgV3xRERErkSUmg5r6jsBJnYiIpIHjrETERGRs2GLnYiIZEGAlWPsNovEvpjYiYhIHrjyHBEREVlr8eLF6NChAzQaDZKSkvDzzz83W3bZsmXo168f/P394e/vj5SUlL8sbwoTOxERycKlx92sOSy1du1aZGRkYNasWdi7dy/i4+MxZMgQXLhwwWT57Oxs3H///fjhhx+wa9cuREZGYvDgwTh79qzZ92RiJyIieZBscFhowYIFmDhxItLS0hAXF4elS5fC09MTK1asMFn+o48+wqRJk5CQkICuXbti+fLlEEURWVlZZt+TiZ2IiMgClZWVRkdDQ4PJco2NjdizZw9SUlIM5xQKBVJSUrBr1y6z7lVbWwutVouAgACz42NiJyIiWRAkyeoDACIjI+Hr62s4MjMzTd6vpKQEer0eISEhRudDQkJQWFhoVszPPfccwsLCjL4cXAtnxRMRkTyIfxzW1AdQUFAAHx8fw2m1Wm1VWM15+eWXsWbNGmRnZ0Oj0Zhdj4mdiIjIAj4+PkaJvTlBQUFQKpUoKioyOl9UVITQ0NC/rPvqq6/i5Zdfxvfff48ePXpYFB+74omISBZs1RVvLpVKhcTERKOJb5cmwiUnJzdb75VXXsHcuXOxadMm9O7d2+L3yRY7ERHJgwPWis/IyEBqaip69+6Nvn37YuHChaipqUFaWhoAYOzYsQgPDzeM0//nP//BzJkzsXr1anTo0MEwFu/l5QUvLy+z7snETkRE8uCAledGjx6N4uJizJw5E4WFhUhISMCmTZsME+ry8/OhUFzuPF+yZAkaGxtxzz33GF1n1qxZeOGFF8y6JxM7ERGRHaWnpyM9Pd3kz7Kzs41enzp1yur7MbETEZEstHT1uCvrOwMm9uvAP+88hnvuPQL/gHqcPOmHJYt74WhuoMmy7aMq8NDYA+jcuRQhobV4e0kC1q+LvapcYGAtxk34Db37nIdarce5c154/dW+OHbM/EUOyPbuiz+Ah3vnIKhNLXKLA5H5wy04UBhisuzdNx7Cnd1y0TmoFABwqKgt3vgxyah8oGctnu63G8lRBfBWN2LP2XbI3HIL8sv9WuPt0DXs/8APe5cHorZYiaBuDRgwswih8fUmyx76zBffP9fO6JxSJWLyoaMmy2+ZEYIDH/uj3/NF6JlWZvPYXRI3gaHW0H9APh55NAcffXgDHp80GHkn/fDiS1vh62f6w69R61BY2AYrV8Sj9KLp5xq9vBrx2utZ0OkEzHi+Px6dOBTL30lAdbXKnm+FrmFIl+OYOuBHLN3dG6M+vAdHiwPx9siNCPCoNVm+T8Q5fJPbGeP+NxwPfjwShVVeeHvkRgR7Vf9RQsIbwzYhwrcST3xxG0Z9eA/OV3pj2T0b4OGmbb03RiYd/cob218KRtLjJbjvi1MI6tqAL9IiUXtR2WwdlZce43cdMxxp206YLHfiOy8U5nigTQh/z3Q1hyb2zMxM9OnTB97e3ggODsaIESOQm5vryJBa3V135+Kbb6Kx+bto5Of74s03eqOhwQ2Dh+SZLH/0aCDeXZaArdntodWa/vXdO+owios98fprSTiaG4iiQi/s3ROK8+fNm1FJ9jE2cT8+OxCH9Qe74mRpAOZ8PwB1Onfc1f2IyfLTvknB2v3dkVschLwyf8zaPBAKQUJSZNNmEFF+FYgPK8LcrP44WBSMU2X+mPt9f6jddLit67HWfGtkwr4VAeg+ugJx91QgsHMj/j63EG4eIg79z7f5SgLQpq3ecHgG6a8qUl3ohuzZIRjy2jko2OdqEUG0/nAGDk3sW7duxeTJk7F7925s3rwZWq0WgwcPRk1NjSPDajVubnp07lyGnH2Xu1YlSUDOvhB061bS4uv+Lfkcjh0LwL//70d8/Ml6vPXfbzH0NtPf/Kl1uCn0iAspxu7TEYZzEgTsPh2O+HZFf1HzMo2bDm5KERX1Tatcqdya/ug36C63ACUI0OqV6BVu3nKVZB/6RuDCAQ0ib778t0xQAJE31eL8Po9m62lrFVjZvxNW3NIJGx4Nx8Wjxr1skgh8N6UdEieWIrBLo93id1mXuuKtOZyAQ7/vbdq0yej1qlWrEBwcjD179qB///5XlW9oaDBabL+ystLuMdqTj08jlEoJZWXGXeplZRpERLb8vYW2q8Yd/zyOzz+LxdqP49AlthSPTdoHnU6B7zd3tDZsagF/j3q4KSRcrDX+o36x1hMdA8rNusbT/XajuLoNduc3fTnIK/XDuUovPHXLT5jz/QDUat0wNvE3hHrXIKiN6e59ah11ZW6Q9AI8A3VG5z2DdCg76Wmyjn/HBqS8fB5BsQ1oqFJg7/JA/G9UFMZ8kwfvdk3X+fXtAAhKID6VY+rUvOtqjL2iogIAmt3FJjMz02jh/cjIyNYMz2kIAnD8mD/eW9kDJ07445uvO2HTN9G4/Q622p3V+D57cVvX43jqy6Fo1Dd9H9eJSjz95VBE+Zfjx8kr8MsTy9An8iy257V3loYFXaFdr3p0u6sSbeMaEJFUhzv+ewYeAXocWOMHALhwQI397wXg1lfOQxAcG6vTcsC2rY5w3YzQiKKIp556CjfffDO6d+9ussz06dORkZFheF1ZWenUyb2yUgW9XoC/v/FEOX//epSVmr/g/5+VlmqQn2+8jnFBvg9uvuVMi69J1imr00AnCgj0rDM6H+hZi4s1pltwl6Qm5mBcn32Y+NmdOFpi/LTEoQttce+Ho+ClaoC7UkRZnQc+uv8zHCpqa/P3QObz8NdBUEqovWj8J7a2xA2eQbpmahlTugNt4+pRcbqpO/7sL56ovajEyv6dDGUkvYAdmcHIWRWAtK384n4tLVkW9s/1ncF1k9gnT56MAwcOYMeOHc2WUavVdttFxxF0OiWOHfNHQkIRdu1s6l4VBAkJCUX48svOLb7uoYNBiIioMjoXHlGFC0V/nUDIfnSiEoeK2iKp/RlsOdE0HCJAwt/an8XHOaa/yAJAWu99mJi0F499fgcOFQU3W666selz0d6vHDeEFOOtnX1t+wbIIkoVENy9HgU726DTrU1PMUgiULDTE/EPmdeNLuqBi0fViBrQNE7fdUQF2t9sPP9ofVokug6vRNw9FbZ9A+TUrovEnp6ejo0bN2Lbtm2IiIi4dgUXsu6zWDwz9SccOxaA3COBGDEyF2qNDpu/bfrj/8zU3bh40ROrVjTt7uPmpkf79k3j727uIgKD6hAdXYa6ejecP+cNAFj/eRe8tjALo+87hG3bIhEbW4rbbj+BRQst30yAbOf9PfGYN3QLDha1xe+FIXio12/wcNdi/cGuAIB5Q7NwoboN3tjxNwDAuD77MDn5Zzz3TQrOVvgg0LNp3LxW6446rTsAYHDnEyit06Cwyhudgy7iuYE/YsuJDth12nl7slxFz3Gl2Dy1HUJurENIj3rkrPKHrk5hSMLfTWmHNiE63Dy1GADw05uBCE2og1+UFg2VTWPslWfdccOocgCAh78ID3/jCXMKN8CzrQ7+0ZxIZxaZPMfu0MQuSRIef/xxrFu3DtnZ2ejYUX4Tu7ZtbQ9f3wY8OPYAAvzrceKkH2Y8PwDl5U1d8cHBtZCkywNqAYH1WLz0O8Pre+7NxT335uK3/W3x3NS/A2h6JG7u7Fvw8Ljf8MCDB1FY2AZvL+mJH7Z0aNX3Rsa+PRqDAM86TL7pFwR51uJIcRAe+/yfuFjb1JPSzrva6Hc9qsdBqNxEvH7nd0bX+e+u3liyqw8AIMirBlMH/ohAzzoU13hiw6FYLN2d2HpviprV5Y4q1F1UYvfCtqgpVqJtXAOGrygwPMJWdc4dwhWznBoqlNjyfDvUFCuh8RUR3L0e935yGoGdmbRtRoJ1+7E7R16HIEmO+woyadIkrF69Gl988QViYy+vnubr6wsPj+YfCbmksrISvr6++HvcVLgpXaeLnkw7M5Sr5snJy4+tcHQI1Apqq/S4L+EwKioqzNrjvCUMuaLnNLgpWz5/Saevx5Z9L9s1Vltw6Kz4JUuWoKKiAgMHDkS7du0Mx9q1ax0ZFhERkdNyeFc8ERFRq5Bg5Ri7zSKxq+ti8hwREZHdyWTy3HW1QA0RERFZhy12IiKSBxGANav2OckmMEzsREQkC3JZeY5d8URERC6ELXYiIpIHmUyeY2InIiJ5kEliZ1c8ERGRC2GLnYiI5EEmLXYmdiIikgc+7kZEROQ6+LgbEREROR222ImISB44xk5ERORCRAkQrEjOonMkdnbFExERuRC22ImISB7YFU9ERORKrEzscI7Ezq54IiIiF8IWOxERyQO74omIiFyIKMGq7nTOiiciIqLWxhY7ERHJgyQ2HdbUdwJM7EREJA8cYyciInIhHGMnIiIiZ8MWOxERyQO74omIiFyIBCsTu80isSt2xRMREbkQttiJiEge2BVPRETkQkQRgBXPoovO8Rw7u+KJiIhcCFvsREQkD+yKJyIiciEySezsiiciInIhbLETEZE8yGRJWSZ2IiKSBUkSIVmxQ5s1dVsTEzsREcmDJFnX6uYYOxEREbU2ttiJiEgeJCvH2J2kxc7ETkRE8iCKgGDFOLmTjLGzK56IiMiFsMVORETywK54IiIi1yGJIiQruuKd5XE3dsUTERG5ELbYiYhIHtgVT0RE5EJECRBcP7GzK56IiMiFsMVORETyIEkArHmO3Tla7EzsREQkC5IoQbKiK15yksTOrngiIpIHSbT+aIHFixejQ4cO0Gg0SEpKws8//9xs2YMHD+Luu+9Ghw4dIAgCFi5caPH9mNiJiIjsZO3atcjIyMCsWbOwd+9exMfHY8iQIbhw4YLJ8rW1tYiOjsbLL7+M0NDQFt2TiZ2IiGRBEiWrD0stWLAAEydORFpaGuLi4rB06VJ4enpixYoVJsv36dMH8+fPx3333Qe1Wt2i98nETkRE8mCjrvjKykqjo6GhweTtGhsbsWfPHqSkpBjOKRQKpKSkYNeuXXZ7m049ee7SRAad3vR/VHIt+oZ6R4dArai2Su/oEKgV1FY3/Z5bY2KaDlqr1qfRQQsAiIyMNDo/a9YsvPDCC1eVLykpgV6vR0hIiNH5kJAQHDlypOWBXINTJ/aqqioAwLbcRQ6OhFrFIUcHQK3pPn6sZaWqqgq+vr52ubZKpUJoaCh2FH5t9bVCQ0Oxf/9+aDQaw7mWdpnbi1Mn9rCwMBQUFMDb2xuCIDg6nFZTWVmJyMhIFBQUwMfHx9HhkB3xdy0fcv1dS5KEqqoqhIWF2e0eGo0GeXl5aGxstPpaKpXKKKn/laCgICiVShQVFRmdLyoqavHEOHM4dWJXKBSIiIhwdBgO4+PjI6s/AHLG37V8yPF3ba+W+pU0Go3ZCdlWVCoVEhMTkZWVhREjRgAARFFEVlYW0tPT7XZfp07sRERE17OMjAykpqaid+/e6Nu3LxYuXIiamhqkpaUBAMaOHYvw8HBkZmYCaJpwd+jQIcP/P3v2LHJycuDl5YWYmBiz7snETkREZCejR49GcXExZs6cicLCQiQkJGDTpk2GCXX5+flQKC4/oHbu3Dn07NnT8PrVV1/Fq6++igEDBiA7O9usezKxOyG1Wo1Zs2ZddxM2yPb4u5YP/q5dV3p6erNd739O1h06dLD6CQFBcpbFb4mIiOiauEANERGRC2FiJyIiciFM7ERERC6EiZ2IiMiFMLE7GUv29SXntW3bNtx5550ICwuDIAhYv369o0MiO8nMzESfPn3g7e2N4OBgjBgxArm5uY4Oi5wYE7sTsXRfX3JeNTU1iI+Px+LFix0dCtnZ1q1bMXnyZOzevRubN2+GVqvF4MGDUVNT4+jQyEnxcTcnkpSUhD59+uCtt94C0LQ0YWRkJB5//HFMmzbNwdGRvQiCgHXr1hmWpCTXVlxcjODgYGzduhX9+/d3dDjkhNhidxKO2teXiFpXRUUFACAgIMDBkZCzYmJ3En+1r29hYaGDoiIiWxJFEU899RRuvvlmdO/e3dHhkJPikrJERNeJyZMn48CBA9ixY4ejQyEnxsTuJBy1ry8RtY709HRs3LgR27Ztk/V21GQ9dsU7iSv39b3k0r6+ycnJDoyMiKwhSRLS09Oxbt06bNmyBR07dnR0SOTk2GJ3Itfa15dcR3V1NY4fP254nZeXh5ycHAQEBKB9+/YOjIxsbfLkyVi9ejW++OILeHt7G+bM+Pr6wsPDw8HRkTPi425O5q233sL8+fMN+/ouWrQISUlJjg6LbCw7OxuDBg266nxqaipWrVrV+gGR3QiCYPL8ypUr8fDDD7duMOQSmNiJiIhcCMfYiYiIXAgTOxERkQthYiciInIhTOxEREQuhImdiIjIhTCxExERuRAmdiIiIhfCxE5ERORCmNiJrPTwww9jxIgRhtcDBw7EU0891epxZGdnQxAElJeXN1tGEASsX7/e7Gu+8MILSEhIsCquU6dOQRAE5OTkWHUdIjIPEzu5pIcffhiCIEAQBKhUKsTExGDOnDnQ6XR2v/fnn3+OuXPnmlXWnGRMRGQJbgJDLmvo0KFYuXIlGhoa8PXXX2Py5Mlwd3fH9OnTryrb2NgIlUplk/sGBATY5DpERC3BFju5LLVajdDQUERFReFf//oXUlJS8OWXXwK43H0+b948hIWFITY2FgBQUFCAUaNGwc/PDwEBARg+fDhOnTpluKZer0dGRgb8/PwQGBiIZ599Fn/ebuHPXfENDQ147rnnEBkZCbVajZiYGLz77rs4deqUYaMXf39/CIJg2PRDFEVkZmaiY8eO8PDwQHx8PD799FOj+3z99dfo0qULPDw8MGjQIKM4zfXcc8+hS5cu8PT0RHR0NGbMmAGtVntVubfffhuRkZHw9PTEqFGjUFFRYfTz5cuXo1u3btBoNOjatSv++9//WhwLEdkGEzvJhoeHBxobGw2vs7KykJubi82bN2Pjxo3QarUYMmQIvL29sX37dvz444/w8vLC0KFDDfVee+01rFq1CitWrMCOHTtQWlqKdevW/eV9x44di48//hiLFi3C4cOH8fbbb8PLywuRkZH47LPPAAC5ubk4f/483njjDQBAZmYm3n//fSxduhQHDx7E008/jQcffBBbt24F0PQFZOTIkbjzzjuRk5ODCRMmYNq0aRb/N/H29saqVatw6NAhvPHGG1i2bBlef/11ozLHjx/HJ598gg0bNmDTpk3Yt28fJk2aZPj5Rx99hJkzZ2LevHk4fPgwXnrpJcyYMQPvvfeexfEQkQ1IRC4oNTVVGj58uCRJkiSKorR582ZJrVZLU6ZMMfw8JCREamhoMNT54IMPpNjYWEkURcO5hoYGycPDQ/r2228lSZKkdu3aSa+88orh51qtVoqIiDDcS5IkacCAAdKTTz4pSZIk5ebmSgCkzZs3m4zzhx9+kABIZWVlhnP19fWSp6entHPnTqOy48ePl+6//35JkiRp+vTpUlxcnNHPn3vuuauu9WcApHXr1jX78/nz50uJiYmG17NmzZKUSqV05swZw7lvvvlGUigU0vnz5yVJkqROnTpJq1evNrrO3LlzpeTkZEmSJCkvL08CIO3bt6/Z+xKR7XCMnVzWxo0b4eXlBa1WC1EU8cADD+CFF14w/PzGG280Glffv38/jh8/Dm9vb6Pr1NfX48SJE6ioqMD58+eRlJRk+Jmbmxt69+59VXf8JTk5OVAqlRgwYIDZcR8/fhy1tbW49dZbjc43NjaiZ8+eAIDDhw8bxQEAycnJZt/jkrVr12LRokU4ceIEqqurodPp4OPjY1Smffv2CA8PN7qPKIrIzc2Ft7c3Tpw4gfHjx2PixImGMjqdDr6+vhbHQ0TWY2InlzVo0CAsWbIEKpUKYWFhcHMz/ufepk0bo9fV1dVITEzERx99dNW12rZt26IYPDw8LK5TXV0NAPjqq6+MEirQNG/AVnbt2oUxY8Zg9uzZGDJkCHx9fbFmzRq89tprFse6bNmyq75oKJVKm8VKROZjYieX1aZNG8TExJhdvlevXli7di2Cg4OvarVe0q5dO/z000/o378/gKaW6Z49e9CrVy+T5W+88UaIooitW7ciJSXlqp9f6jHQ6/WGc3FxcVCr1cjPz2+2pd+tWzfDRMBLdu/efe03eYWdO3ciKioKzz//vOHc6dOnryqXn5+Pc+fOISwszHAfhUKB2NhYhISEICwsDCdPnsSYMWMsuj8R2QcnzxH9YcyYMQgKCsLw4cOxfft25OXlITs7G0888QTOnDkDAHjyySfx8ssvY/369Thy5AgmTZr0l8+gd+jQAampqRg3bhzWr19vuOYnn3wCAIiKioIgCNi4cSOKi4tRXV0Nb29vTJkyBU8//TTee+89nDhxAnv37sWbb75pmJD22GOP4dixY5g6dSpyc3OxevVqrFq1yqL327lzZ+Tn52PNmjU4ceIEFi1aZHIioEajQWpqKvbv34/t27fjiSeewKhRoxAaGgoAmD17NjIzM7Fo0SIcPXoUv//+O1auXIkFCxZYFA8R2QYTO9EfPD09sW3bNrRv3x4jR45Et27dMH78eNTX1xta8M888wweeughpKamIjk5Gd7e3rjrrrv+8rpLlizBPffcg0mTJqFr166YOHEiampqAADh4eGYPXs2pk2bhpCQEKSnpwMA5s6dixkzZiAzMxPdunXD0KFD8dVXX6Fjx44Amsa9P/vsM6xfvx7x8fFYunQpXnrpJYve77Bhw/D0008jPT0dCQkJ2LlzJ2bMmHFVuZiYGIwcORK33347Bg8ejB49ehg9zjZhwgQsX74cK1euxI033ogBAwZg1apVhliJqHUJUnOzfoiIiMjpsMVORETkQpjYiYiIXAgTOxERkQthYiciInIhTOxEREQuhImdiIjIhTCxExERuRAmdiIiIhfCxE5ERORCmNiJiIhcCBM7ERGRC/l/jDXBip1/klYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.60      0.61       599\n",
      "           2       0.40      0.46      0.43       440\n",
      "           3       0.59      0.54      0.57       408\n",
      "\n",
      "    accuracy                           0.54      1447\n",
      "   macro avg       0.54      0.53      0.54      1447\n",
      "weighted avg       0.55      0.54      0.54      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
