{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#Modelo BETO\n",
    "#Libreria transformers (modelo BERT predefinido para la clasificación (BertForSequenceClassification))\n",
    "#Libreria sera BERT + Capa de clasificación por encima\n",
    "#Debemos tokenizar nuestro dataset (tokens + attention mask + max_length)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "MAX_LEN = 32\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Environment stopwords for train\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_train['review']=df_train['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment stopwords for dev\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_dev['review']=df_dev['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 32\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('finiteautomata/beto-sentiment-analysis',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained('finiteautomata/beto-sentiment-analysis', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31006, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.67      0.69       599\n",
      "           2       0.50      0.58      0.54       440\n",
      "           3       0.71      0.64      0.67       408\n",
      "\n",
      "    accuracy                           0.64      1447\n",
      "   macro avg       0.64      0.63      0.63      1447\n",
      "weighted avg       0.65      0.64      0.64      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-08 14:05:35.979464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#Model BETO with new dataclearing\n",
    "#Libreria transformers (modelo BERT predefinido para la clasificación (BertForSequenceClassification))\n",
    "#Libreria sera BERT + Capa de clasificación por encima\n",
    "#Debemos tokenizar nuestro dataset (tokens + attention mask + max_length)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "MAX_LEN = 32\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CUSTOM DEFINED FUNCTIONS TO CLEAN THE TWEETS\n",
    "\n",
    "\n",
    "#Remove punctuations, links, mentions and \\r\\n new line characters\n",
    "def strip_all_entities(text): \n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_new_train = []\n",
    "review_new_dev = []\n",
    "for t in df_train.review:\n",
    "    review_new_train.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(t)))))\n",
    "\n",
    "for t in df_dev.review:\n",
    "    review_new_dev.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(t)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review'] = review_new_train\n",
    "df_dev['review'] = review_new_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 32\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('finiteautomata/beto-sentiment-analysis',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained('finiteautomata/beto-sentiment-analysis', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31006, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.82      0.84       599\n",
      "           2       0.67      0.75      0.71       440\n",
      "           3       0.84      0.78      0.81       408\n",
      "\n",
      "    accuracy                           0.79      1447\n",
      "   macro avg       0.79      0.78      0.79      1447\n",
      "weighted avg       0.79      0.79      0.79      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
