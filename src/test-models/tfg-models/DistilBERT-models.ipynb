{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#Modelo distilBERT\n",
    "#Libreria transformers (modelo BERT predefinido para la clasificación (BertForSequenceClassification))\n",
    "#Libreria sera BERT + Capa de clasificación por encima\n",
    "#Debemos tokenizar nuestro dataset (tokens + attention mask + max_length)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import DistilBertTokenizerFast, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "from keras.models import Model\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Pandas options\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "MAX_LEN = 38\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  review  \\\n",
      "0  @Jorge_LBU Espero que te mejores pronto, vomitar es muy desagradable    \n",
      "\n",
      "   label  \n",
      "0      0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CUSTOM DEFINED FUNCTIONS TO CLEAN THE TWEETS\n",
    "\n",
    "\n",
    "#Remove punctuations, links, mentions and \\r\\n new line characters\n",
    "def strip_all_entities(text): \n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(df):\n",
    "    cleaned_reviews = []\n",
    "    for t in df.review:\n",
    "        cleaned_reviews.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(t)))))\n",
    "    return cleaned_reviews\n",
    "\n",
    "\n",
    "review_new_train = clean_reviews(df_train)\n",
    "review_new_dev = clean_reviews(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     review  label\n",
      "0  espero que te mejores pronto vomitar es muy desagradable      0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_new_train = []\n",
    "review_new_dev = []\n",
    "for t in df_train.review:\n",
    "    review_new_train.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(t)))))\n",
    "\n",
    "for t in df_dev.review:\n",
    "    review_new_dev.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(t)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review'] = review_new_train\n",
    "df_dev['review'] = review_new_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 38\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True,)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGwCAYAAABb6kfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABB/klEQVR4nO3de1xUdf4/8NeZAWa4DjcBQRSVvJAKismS620XxXRTayszS6S0XRUzyVK3X5qXxHLXXNOVLprdTNpKTXMxw/CSmt+8paYYiooKCCIgyHXO+f1Bjk0MOsPcnDmv5+NxHvuYz3w+57xnJ3nP53I+R5AkSQIRERE5BYW9AyAiIiLLYWInIiJyIkzsREREToSJnYiIyIkwsRMRETkRJnYiIiInwsRORETkRFzsHYA5RFHE5cuX4e3tDUEQ7B0OERGZSJIkXL9+HaGhoVAorNfXrKmpQV1dndnncXNzg1qttkBE1uPQif3y5csIDw+3dxhERGSm/Px8tGnTxirnrqmpQft2Xii8ojX7XCEhIcjLy7urk7tDJ3Zvb28AwPlDEfDx4qyCs3tk6F/sHQLZkPbseXuHQDbQgHrswVbd33NrqKurQ+EVLc4fjICPd8tzRcV1Ee1iz6Guro6J3VpuDr/7eCnM+rLIMbgoVfYOgWxIEFztHQLZwq+bmttiOtXLW4CXd8uvI8IxpnwdOrETEREZSyuJ0JrxdBStJFouGCtiYiciIlkQIUFEyzO7OW1tiePXREREToQ9diIikgURIswZTDevte0wsRMRkSxoJQlaqeXD6ea0tSUOxRMREVnRypUrERERAbVajbi4OBw4cKDZugMHDoQgCE2O4cOHG309JnYiIpKFm4vnzDlMlZGRgdTUVMydOxeHDh1CdHQ0EhMTceXKFYP1v/zySxQUFOiO48ePQ6lU4tFHHzX6mkzsREQkCyIkaM04WpLYly5diokTJyI5ORlRUVFIT0+Hh4cH1qxZY7C+v78/QkJCdMf27dvh4eHBxE5ERGQtFRUVekdtba3BenV1dTh48CASEhJ0ZQqFAgkJCdi3b59R11q9ejUef/xxeHp6Gh0fEzsREcmCpYbiw8PDodFodEdaWprB65WUlECr1SI4OFivPDg4GIWFhXeM98CBAzh+/DgmTJhg0ufkqngiIpIFS62Kz8/Ph4+Pj65cpbLOdterV69G9+7d0adPH5PaMbETERGZwMfHRy+xNycwMBBKpRJFRUV65UVFRQgJCblt26qqKqxfvx7z5883OT4OxRMRkSyIFjhM4ebmhtjYWGRlZd2KQRSRlZWF+Pj427b973//i9raWjz55JMmXpU9diIikombq9vNaW+q1NRUJCUloXfv3ujTpw+WLVuGqqoqJCcnAwDGjRuHsLCwJvP0q1evxqhRoxAQEGDyNZnYiYhIFrQSzHy6m+ltRo8ejeLiYsyZMweFhYWIiYlBZmambkHdhQsXoFDoD57n5ORgz549+Oabb1oUJxM7ERGRFaWkpCAlJcXge9nZ2U3KOnfuDMmMRX5M7EREJAstmSf/fXtHwMRORESyIEKAFoJZ7R0BV8UTERE5EfbYiYhIFkSp8TCnvSNgYiciIlnQmjkUb05bW+JQPBERkRNhj52IiGRBLj12JnYiIpIFURIgSmasijejrS1xKJ6IiMiJsMdORESywKF4IiIiJ6KFAlozBqq1FozFmpjYiYhIFiQz59glzrETERGRrbHHTkREssA5diIiIieilRTQSmbMsTvIlrIciiciInIi7LETEZEsiBAgmtGfFeEYXXYmdiIikgW5zLFzKJ6IiMiJsMdORESyYP7iOQ7FExER3TUa59jNeAgMh+KJiIjI1thjJyIiWRDN3Cueq+KJiIjuIpxjJyIiciIiFLK4j51z7ERERE6EPXYiIpIFrSRAa8ajV81pa0tM7EREJAtaMxfPaTkUT0RERLbGHjsREcmCKCkgmrEqXuSqeCIiorsHh+KJiIjI4bDHTkREsiDCvJXtouVCsSomdiIikgXzN6hxjEFux4iSiIiIjMIeOxERyYL5e8U7Rl+YiZ2IiGRBLs9jZ2InIiJZYI+dbOar9wPx+aoglBa7oENUNSYvvIQuPW8YrPviXyPx0z6vJuV9/lyOBR/loaEeWPt6a/zfDh8UnHeDp4+Inv2u45l/XEZASIO1PwrdwV8eOou/Pv4L/PxrkXdGg1X/7oHTJ/0M1m0bUYGnnjmJyE5lCG5djbff6oZN/43Uq/N+xjYEt65u0nbLhvb4z5vRVvkMZLwHx5fgkUlX4N+qAWd/dsd//l8Yco54GKzbrlMNxr1YiMgeNxASXo/0OaHY8F4rvTrd4irx6ORi3NP9BgJCGvDq0xHYl6mxxUchB3JX/PxYuXIlIiIioFarERcXhwMHDtg7JJvJ3uSLd+aFYmxqIVZuy0GHqGq8/EQHlJUY/s31ynt5+PTIcd3x9nenoFBK6PeXcgBAbbUCucc88MTzRVi57TTmvJeHi2dUmDu+gy0/FhnQ/08XMXHKcaxb2wVTJwzE2VwfLPjnXmh8aw3WV6m1KLjsifffvhelV1UG60x7diDGjhqqO/4x/X4AwO7vQq32Ocg4A0Zcw7NzL+OTpSGYktgJZ39W47V1Z6EJqDdYX+UuouCCG9Ysao2rRYb//as9RJw9ocaKf7SxZuhO6+YGNeYcjsDuUWZkZCA1NRVz587FoUOHEB0djcTERFy5csXeodnEl++0wtAnriLx8VK061SL516/CJW7iG2f+hus7+OnhX9Qg+44tMsbancR/R8sAwB4+ohYnHEGA0aUITyyFl1jb2DKaxfxy08euHLR1YafjH7vocfOIHNLO2z/Xzvkn/fBin/FoLZGiSHDzxus/8spP6xZ1Q27drRBfZ3hf6oV5SpcK1Xrjj73F+LyRU8cOxJozY9CRnj42RJkrvPHNxn+uPCLGstntkFttYDEMaUG658+6oH3FoRi5yY/1NcZnsv98TsffPBGa+xlL71FREkw+3AEdk/sS5cuxcSJE5GcnIyoqCikp6fDw8MDa9assXdoVldfJ+CXnzzQq1+lrkyhAHr2q8TPBz2NOse2T/0xYOQ1qD2a3zqhqkIJQZDgqdGaHTO1jIuLiMhOZTjy462hVUkScORgK3S51/Af+pZcY9Dgi/hma1vAQRb5OCsXVxH39LiBQ7u9dWWSJODwbm9ExRqeZiOyFLsm9rq6Ohw8eBAJCQm6MoVCgYSEBOzbt69J/draWlRUVOgdjqyiVAlRK8C3lf7QnF9gPa4V33n5w6nDHjh3yh1Dn2g+MdTVCFj9WigGjroGT29H2TfJ+fhoaqF0kXDtmlqvvKxUBX9/w0PxporvVwAvr3p8+7+2FjkftZyPvxZKF6Dsd/+Or5W4wK8V17rYi2jmMDw3qDFCSUkJtFotgoOD9cqDg4NRWFjYpH5aWho0Go3uCA8Pt1Wod6Vtn/qjfdfqZhfaNdQDr/0tApCAqYsv2jY4srkhw8/jxx+CUHrV3d6hEN2Vbj7dzZzDEThGlL+aPXs2ysvLdUd+fr69QzKLj78WCqWEsmL9ue9rJa53/FVfc0OB7E1+SBxz1eD7N5N60SU3pK0/w966nVWUq6BtEODnV6NX7utfi9JSwwvjTBEUfAMxsVew7esIs89F5qsoVULbAPj+7t+xX2CDUaNxROawa2IPDAyEUqlEUVGRXnlRURFCQkKa1FepVPDx8dE7HJmrm4R7etzA4T23bl8TReDIHi9ExVbdtu2uzb6orxPw54evNXnvZlK/lKfC4oxc+Phzbt3eGhoUyD3ti+jYYl2ZIEiI6VWMUycML5Q0xeBh51FepsKBfcF3rkxW11CvwC8/eaDnH6/rygRBQswfK/HzQcO3u5H1aSGYfTgCuyZ2Nzc3xMbGIisrS1cmiiKysrIQHx9vx8hs5+Fni/G/dQHY/pkfLvyiwluz2qDmhgJDHm+cN3/jubZYs6h1k3aZn/rj/sTyJkm7oR5YMLE9Th/1wMwV5yFqBZRecUHpFZdmV9qSbWz4rCOG/uU8/jz0AsLbXceUF45C5a7F9q2Nc+Iv/OMgxj97QlffxUVEh8gydIgsg4urhIDAGnSILEPrsEq98wqChMEPXMC3mW0hah1qEM6pfflOIB54ohQJj5YiPLIGUxdfhNpDxDfrG3/IvfjvC0ieXaCr7+IqosO91ehwbzVcXSUEtK5Hh3urERpxaw2G2kOrqwMAIeF16HBvNVqF1dn2wzkouQzF231MKDU1FUlJSejduzf69OmDZcuWoaqqCsnJyfYOzSYGjixD+VUXfLikNa4Vu6DDvdV47ZOzuqH44ktuUPzuv6X8XBVOHPDCok9zm5yvpNAN+79pvBVm8uAueu+98Xkuou+vbNKGbGPXjjbw8a3DU0+fhJ9/Lc7majBnRjzKfl1Q1yr4BkTpVn3/wGqsWJOte/3ImFw8MiYXPx0OwKxp/XTlMb2LERRSje1ft7PVRyEj7PzKD5oALca9WAi/Vg04e8IdL49tj7KSxqm3VmF1EH8zQxYQ3IBV20/rXj86qRiPTirG0b2eeOmRxo2JOkVXY8kXZ3R1/j7vMgDgmww//Gs6F01SI0GSJOnO1axrxYoVWLJkCQoLCxETE4Ply5cjLi7uju0qKiqg0Whw7XQH+Hg7xi8parlh/R+ydwhkQ9rcPHuHQDbQINUjG5tQXl5utenVm7lizg8JUHu1fD+Pmsp6zI/71qqxWoLde+wAkJKSgpSUFHuHQURETszc4XRHGYp3jCiJiIjMdPMhMOYcLWHqtullZWWYMmUKWrduDZVKhU6dOmHr1q1GX++u6LETERE5o5vbpqenpyMuLg7Lli1DYmIicnJyEBQU1KR+XV0dBg8ejKCgIHz++ecICwvD+fPn4evra/Q1mdiJiEgWJDOfxy792vb3u56qVCqoVIb3o/jttukAkJ6ejq+//hpr1qzBrFmzmtRfs2YNSktLsXfvXri6Nq4HiIiIMClODsUTEZEsWGooPjw8XG8X1LS0NIPXM3XbdAD46quvEB8fjylTpiA4OBjdunXDokWLoNUavx8Je+xEREQmyM/P11sV31xv/Xbbpp86dcpgm7Nnz2LHjh0YO3Ystm7ditzcXEyePBn19fWYO3euUfExsRMRkSyY++jVm22tufOpKIoICgrCO++8A6VSidjYWFy6dAlLlixhYiciIvqtm09pM6e9KUzdNh0AWrduDVdXVyiVSl1Z165dUVhYiLq6Ori5ud3xupxjJyIisoKWbJvet29f5ObmQvzNtoSnT59G69atjUrqABM7ERHJxM2heHMOU6WmpuLdd9/FBx98gJMnT2LSpEl626aPGzcOs2fP1tWfNGkSSktLMW3aNJw+fRpff/01Fi1ahClTphh9TQ7FExGRLIhQQDSjP9uStqNHj0ZxcTHmzJmj2zY9MzNTt6DuwoULUPzmgSDh4eHYtm0bpk+fjh49eiAsLAzTpk3DzJkzjb4mEzsREZEV3W7b9Ozs7CZl8fHx2L9/f4uvx8RORESyoJUEaM1YFW9OW1tiYiciIlmw1O1udzsmdiIikgXJzKe7SXy6GxEREdkae+xERCQLWgjQmvEQGHPa2hITOxERyYIomTdPLkoWDMaKOBRPRETkRNhjJyIiWRDNXDxnTltbYmInIiJZECFANGOe3Jy2tuQYPz+IiIjIKOyxExGRLHDnOSIiIicilzl2x4iSiIiIjMIeOxERyYIIM/eKd5DFc0zsREQkC5KZq+IlJnYiIqK7h1ye7sY5diIiIifCHjsREcmCXFbFM7ETEZEscCieiIiIHA577EREJAty2SueiZ2IiGSBQ/FERETkcNhjJyIiWZBLj52JnYiIZEEuiZ1D8URERE6EPXYiIpIFufTYmdiJiEgWJJh3y5pkuVCsiomdiIhkQS49ds6xExERORH22ImISBbk0mNnYiciIlmQS2LnUDwREZETYY+diIhkQS49diZ2IiKSBUkSIJmRnM1pa0sciiciInIi7LETEZEs8HnsRERETkQuc+wciiciInIi7LETEZEsyGXxHBM7ERHJglyG4pnYiYhIFuTSY+ccOxERkRNxih77yJyhcPFU2TsMsrYwX3tHQDbU0LG3vUMgG2hoqAG+3WSTa0lmDsU7So/dKRI7ERHRnUgAJMm89o6AQ/FEREROhD12IiKSBRECBO48R0RE5By4Kp6IiIgcDhM7ERHJws0Nasw5WmLlypWIiIiAWq1GXFwcDhw40GzdtWvXQhAEvUOtVpt0PSZ2IiKSBUky/zBVRkYGUlNTMXfuXBw6dAjR0dFITEzElStXmm3j4+ODgoIC3XH+/HmTrsnETkREZCVLly7FxIkTkZycjKioKKSnp8PDwwNr1qxpto0gCAgJCdEdwcHBJl2TiZ2IiGTh5uI5cw4AqKio0Dtqa2sNXq+urg4HDx5EQkKCrkyhUCAhIQH79u1rNs7Kykq0a9cO4eHhGDlyJE6cOGHS52RiJyIiWbBUYg8PD4dGo9EdaWlpBq9XUlICrVbbpMcdHByMwsJCg206d+6MNWvWYNOmTfj4448hiiLuv/9+XLx40ejPydvdiIhIFkRJgGCBp7vl5+fDx8dHV65SWW5L8/j4eMTHx+te33///ejatSvefvttLFiwwKhzMLETERGZwMfHRy+xNycwMBBKpRJFRUV65UVFRQgJCTHqWq6urujZsydyc3ONjo9D8UREJAu2XhXv5uaG2NhYZGVl6cpEUURWVpZer/x2tFotjh07htatWxt9XfbYiYhIFhqTszk7z5neJjU1FUlJSejduzf69OmDZcuWoaqqCsnJyQCAcePGISwsTDdPP3/+fPzhD39AZGQkysrKsGTJEpw/fx4TJkww+ppM7ERERFYyevRoFBcXY86cOSgsLERMTAwyMzN1C+ouXLgAheLW4Pm1a9cwceJEFBYWws/PD7Gxsdi7dy+ioqKMviYTOxERyYK99opPSUlBSkqKwfeys7P1Xr/55pt48803W3Sdm5jYiYhIFiSY90x1Po+diIiIbI49diIikgW5PLaViZ2IiORBJmPxTOxERCQPZvbY4SA9ds6xExERORH22ImISBZa+kz137Z3BEzsREQkC3JZPMeheCIiIifCHjsREcmDJJi3AM5BeuxM7EREJAtymWPnUDwREZETYY+diIjkgRvUEBEROQ+5rIo3KrF/9dVXRp9wxIgRLQ6GiIiIzGNUYh81apRRJxMEAVqt1px4iIiIrMdBhtPNYVRiF0XR2nEQERFZlVyG4s1aFV9TU2OpOIiIiKxLssDhAExO7FqtFgsWLEBYWBi8vLxw9uxZAMArr7yC1atXWzxAIiIiMp7Jif21117D2rVr8cYbb8DNzU1X3q1bN7z33nsWDY6IiMhyBAscdz+TE/uHH36Id955B2PHjoVSqdSVR0dH49SpUxYNjoiIyGI4FG/YpUuXEBkZ2aRcFEXU19dbJCgiIiJqGZMTe1RUFHbv3t2k/PPPP0fPnj0tEhQREZHFyaTHbvLOc3PmzEFSUhIuXboEURTx5ZdfIicnBx9++CG2bNlijRiJiIjMJ5Onu5ncYx85ciQ2b96Mb7/9Fp6enpgzZw5OnjyJzZs3Y/DgwdaIkYiIiIzUor3i+/Xrh+3bt1s6FiIiIquRy2NbW/wQmB9//BEnT54E0DjvHhsba7GgiIiILI5PdzPs4sWLGDNmDL7//nv4+voCAMrKynD//fdj/fr1aNOmjaVjJCIiIiOZPMc+YcIE1NfX4+TJkygtLUVpaSlOnjwJURQxYcIEa8RIRERkvpuL58w5HIDJPfadO3di79696Ny5s66sc+fOeOutt9CvXz+LBkdERGQpgtR4mNPeEZic2MPDww1uRKPVahEaGmqRoIiIiCxOJnPsJg/FL1myBFOnTsWPP/6oK/vxxx8xbdo0/POf/7RocERERGQao3rsfn5+EIRbcwtVVVWIi4uDi0tj84aGBri4uODpp5/GqFGjrBIoERGRWWSyQY1RiX3ZsmVWDoOIiMjKZDIUb1RiT0pKsnYcREREZAEt3qAGAGpqalBXV6dX5uPjY1ZAREREViGTHrvJi+eqqqqQkpKCoKAgeHp6ws/PT+8gIiK6K8nk6W4mJ/aXXnoJO3bswKpVq6BSqfDee+9h3rx5CA0NxYcffmiNGImIiMhIJg/Fb968GR9++CEGDhyI5ORk9OvXD5GRkWjXrh0++eQTjB071hpxEhERmUcmq+JN7rGXlpaiQ4cOABrn00tLSwEAf/zjH7Fr1y7LRkdERGQhN3eeM+dwBCb32Dt06IC8vDy0bdsWXbp0wWeffYY+ffpg8+bNuofCkIk2Xofw2XWgVAt0dIM01RfoojJcN7MKiiWlekWSKyBlhuteCx+UA9/dAIq1jd9wJzdIT2uArs2ck2xqxOCTePTB4/DXVOPMBX+sXBuHnDOtDNZ94E+nMbhfLiLalAEAfskLwJqMXnr1n/rrYQyMz0OrgBtoaFDgl7wAvJ/RC6eaOSfZzqg//YzRDxzTfdfLP4nHqTzD38vw/qcwpG8u2oddAwCcPheI977o3Wz96eO+x4hBp7BiXRy+2N7Nap+BHI/JPfbk5GQcPXoUADBr1iysXLkSarUa06dPx4svvmjSuXbt2oUHH3wQoaGhEAQBGzduNDUcx/fdDQjpZZDG+UBKDwE6ukKYWQxc0zbbRPIUIP43VHdI6/S38pXauECa6gfp3RBI/w4Ggl0az1nW/DnJNgb8IQ9/e+r/8PEXMZj0jxE4e94fabO2w9en2mD96K6F+G5vB7y4MBHT5g5D8VVPLJ79DQL8qnR1LhZosGLtH/DszJGYPu8BFBV7YfE/voHGu8ZWH4sMGNTnLCY9/gM+2NQTz746Emfy/fHGC5nw9Tb8Xcd0KcSO/R0w/fVhmLLwQVwp9cSSGZkI9K1qUvePvc4hquMVFF/zsPbHcC5cPGfY9OnT8dxzzwEAEhIScOrUKaxbtw6HDx/GtGnTTDpXVVUVoqOjsXLlSlPDcBrC59eBYV7AUC8gwhXS836ASgFkNv3HrMdfqX/81p89gVg1EOrSeM5JvhCqJOBs0z3+ybb+OvwE/rejE7btvAcXLvni36vjUVvngsSBvxisv3hlf2ze3gVnzgcg/7Ivlr5zPwQB6NmtQFfnu70dcPh4KAqveOP8RT+kf3wfPD3q0aFtqcFzkm08OuQ4vt7VGZl7OuH8ZT8s/bAvaupc8EC/0wbrv/bOQGz6Lgpn8gOQX+iLf77/RwiChF5Rl/XqBfpW4bmx+/Da2wOh1Zr8J5xkwKz72AGgXbt2aNeuXYvaPvDAA3jggQfMDcFx1UvA6TpIY7xvlSkEoJcKws+1zf84rJYgjLnc+OvxHldIz/gCEa7NX+PrSkieAtCxmTpkEy5KLTq1v4r1m7rryiRJwKHjrRF1T7FR51CptHBxEXG90vC0iotSi2F/Oo3KKlecueBvkbjJdC5KLTpFlOCTr3voyiRJwKGfQ3Fv5BWjzqFSNcBFKaKi6tZ3LQgSZj+7ExmZ3XHuMm8vNpUAM5/uZrFIrMuoxL58+XKjT3izN28NtbW1qK2t1b2uqKiw2rVsolyEIAKS3+963H5KIL/BcJtwF0gv+gMdXIEqEcJn1yE8VwRpdQjQ6jdf575qCAuvArUS4K+E9EYrQKM0fE6yCY1PLZRKCdfK3fXKr5W7Izy03KhzTHjiR1y95oFDx1vrlcf1zMfLz+2Eyq0BpWUemLkoERXX1RaLnUyj8a5p/K4rmn7XbUOM+67/9uj/oaTMAwdP3JpqGzPsJ2i1Ar7Yfq9F4yXnYlRif/PNN406mSAIVk3saWlpmDdvntXO7xDuVTUev5LuVUFILoSwpQpSsuZWvRgVpHeCG388fF0FYcFVSCuCG380kEMaPeInDIzPw4wFQ1Ffr/9P9+jPIfj7rBHQeNfggT/9gv83LRvPvTIcZb9LLOQYxgw7ikF9zmL668NR39D4XXdqV4K/Dj6BZ18dCcfpO95lZHK7m1GJPS8vz9pxGGX27NlITU3Vva6oqEB4ePhtWtzlNApICjRdKHdNC/gbOXfmIgCRrsCl3/Xw3RVAmAIIA6QoFYRxBcD/qoAnuOWvvZRXqKDVCvDT6C+e8tNU41rZ7RPwI8OP4/ERxzBzUSLyDAyx19S64nKRKy4X+eBkbhDWLv0CQwf9gvWbehg4G1lb+XV143ft0/S7Lr3Dj63Hhh7DE8N/wgtLhuLsxVvfdfdOhfD1rkbGPzN0ZUqlhEmPH8AjQ05gzIujLfshnJFMtpQ1e47dllQqFVQqJ7ply1UAOrlBOFwL6Y+/rm4VJeBwLaRRXsadQysBefVAnzsMu4oShHrJUf67dEoNWiVO5wWgZ7cC7P2xcV2KIEjoeW8BNn3Tpdl2jz14DE+M+gmz0wbj9NlAo64lKABXF94FYS8NWiVOnwtEr6gCfH84AkDjd92r62VsyIpqtt3jD/yEsX85gpf+NRSnz+nf5rZ9byQO/qx/B8wbL2zD9r2RyNxzj8U/Azkuh0rszkh6xBvC61eBTm5AFzcIX1wHakQg0RMAICy+CgQqIU3wbWzwYTkQpWpc8V7ZOMeOIi2kYb/+EKgWIXxSAel+dyBA2TgUv6kSKNFCGsBbY+zti6/vxUuTduP02UDk5AbioQd+hlrVgG07G/8wvzRpN0queWDN+lgAwOgHj2Hco4eRtqI/Cou94Ke5AQCornFFTa0r1Kp6PDHqJ+w7GI6rZR7QeNdgxJBTCPSrwq4fIuz1MQnAf7/phlkTduH0uUCcPNsKjww5DrWqAZl7OgEAZk/YieIyD7z3+X0AgMeHHUXyqEN47e2BKCzxgp/Pr991beN3XVGlRkWV/g94rVaB0nJ35Bf62vSzOSz22K2vsrISubm5utd5eXk4cuQI/P390bZtWztGZkODPCCVayGsLW8cgu/oBmlxq1u3sF3R6k2nCZUi8K/SxrpeisbNZ5YH3VoVrxSA/AYIr14FKrSAjwLo7AZpWVDzK+fJZnbubw9fnxokPXIYfr7VOHPeH/9YPBhlvy6oCwqshPSbPx5/GXwKbq4i5k7P1jvPh59H46MvekIrCggPLcfg/mfg412D65Uq5JwJxPR5w3D+IldN29N3BzpA412D8aMO/rpBTQBmLk3ULagLCqiE+Js525GDGr/reSk79M6zdmNPfLCpl01jd1bm7h7nKDvPCZIk2S3U7OxsDBo0qEl5UlIS1q5de8f2FRUV0Gg06L95Mlw8nWiIngybb9wwNDmHBjUXespBQ0MN9n77KsrLy6322O+buSLitdegULf8bhGxpgbnXn7Z5FhXrlyJJUuWoLCwENHR0XjrrbfQp0+fO7Zbv349xowZg5EjR5q0gZtde+wDBw6EHX9XEBGRnNhhKD4jIwOpqalIT09HXFwcli1bhsTEROTk5CAoKKjZdufOncOMGTPQr18/k6/Zom2Ldu/ejSeffBLx8fG4dOkSAOCjjz7Cnj17WnI6IiIi67PQlrIVFRV6x2/3V/m9pUuXYuLEiUhOTkZUVBTS09Ph4eGBNWvWNNtGq9Vi7NixmDdvnu6ha6YwObF/8cUXSExMhLu7Ow4fPqz7QOXl5Vi0aJHJARARETmS8PBwaDQa3ZGWlmawXl1dHQ4ePIiEhARdmUKhQEJCAvbt29fs+efPn4+goCA888wzLYrP5KH4hQsXIj09HePGjcP69et15X379sXChQtbFAQREZG1WWrxXH5+vt4ce3O3YZeUlECr1SI4OFivPDg4GKdOnTLYZs+ePVi9ejWOHDnS4jhNTuw5OTno379/k3KNRoOysrIWB0JERGRVFtp5zsfHxyoL/a5fv46nnnoK7777LgIDW75Y2OTEHhISgtzcXEREROiV79mzp0VzAURERDZh48VzgYGBUCqVKCoq0isvKipCSEhIk/pnzpzBuXPn8OCDD+rKRFEEALi4uCAnJwcdO3a843VNnmOfOHEipk2bhh9++AGCIODy5cv45JNPMGPGDEyaNMnU0xERETklNzc3xMbGIisrS1cmiiKysrIQHx/fpH6XLl1w7NgxHDlyRHeMGDECgwYNwpEjR4zeQt3kHvusWbMgiiL+/Oc/48aNG+jfvz9UKhVmzJiBqVOnmno6IiIim7DHBjWpqalISkpC79690adPHyxbtgxVVVVITk4GAIwbNw5hYWFIS0uDWq1Gt27d9Nr7+voCQJPy2zE5sQuCgJdffhkvvvgicnNzUVlZiaioKHh5Gbm3ORERkT3Y4T720aNHo7i4GHPmzEFhYSFiYmKQmZmpW1B34cIFKBQtuvO8WS3eoMbNzQ1RUc0/zICIiIiAlJQUpKSkGHwvOzv7tm2N2YX190xO7IMGDYIgNL+qcMeOHc2+R0REZDdmDsU77UNgYmJi9F7X19fjyJEjOH78OJKSkiwVFxERkWXx6W6GvfnmmwbLX331VVRWVpodEBEREbWcxWbsn3zyydvufUtERGRXFtor/m5nsae77du3D2ozHodHRERkTXJ5HrvJif3hhx/Wey1JEgoKCvDjjz/ilVdesVhgREREZDqTE7tGo9F7rVAo0LlzZ8yfPx9DhgyxWGBERERkOpMSu1arRXJyMrp37w4/Pz9rxURERGR5MlkVb9LiOaVSiSFDhvApbkRE5HBuzrGbczgCk1fFd+vWDWfPnrVGLERERGQmkxP7woULMWPGDGzZsgUFBQWoqKjQO4iIiO5aTn6rG2DCHPv8+fPxwgsvYNiwYQCAESNG6G0tK0kSBEGAVqu1fJRERETmkskcu9GJfd68efj73/+O7777zprxEBERkRmMTuyS1PhTZcCAAVYLhoiIyFq4QY0Bt3uqGxER0V2NQ/FNderU6Y7JvbS01KyAiIiIqOVMSuzz5s1rsvMcERGRI+BQvAGPP/44goKCrBULERGR9chkKN7o+9g5v05ERHT3M3lVPBERkUOSSY/d6MQuiqI14yAiIrIqzrETERE5E5n02E3eK56IiIjuXuyxExGRPMikx87ETkREsiCXOXYOxRMRETkR9tiJiEgeOBRPRETkPDgUT0RERA6HPXYiIpIHDsUTERE5EZkkdg7FExERORH22ImISBaEXw9z2jsCJnYiIpIHmQzFM7ETEZEs8HY3IiIicjjssRMRkTxwKJ6IiMjJOEhyNgeH4omIiJwIe+xERCQLclk8x8RORETyIJM5dg7FExERORH22ImISBY4FE9ERORMOBRPREREjsYpeuzlGWFQuqntHQZZmbdrnb1DIBs6P1a0dwhkA2K1CHxrm2txKJ6IiMiZyGQonomdiIjkQSaJnXPsREREToSJnYiIZOHmHLs5R0usXLkSERERUKvViIuLw4EDB5qt++WXX6J3797w9fWFp6cnYmJi8NFHH5l0PSZ2IiKSB8kCh4kyMjKQmpqKuXPn4tChQ4iOjkZiYiKuXLlisL6/vz9efvll7Nu3Dz/99BOSk5ORnJyMbdu2GX1NJnYiIiIrWbp0KSZOnIjk5GRERUUhPT0dHh4eWLNmjcH6AwcOxEMPPYSuXbuiY8eOmDZtGnr06IE9e/YYfU0mdiIikgVBksw+AKCiokLvqK2tNXi9uro6HDx4EAkJCboyhUKBhIQE7Nu3747xSpKErKws5OTkoH///kZ/TiZ2IiKSBwsNxYeHh0Oj0eiOtLQ0g5crKSmBVqtFcHCwXnlwcDAKCwubDbO8vBxeXl5wc3PD8OHD8dZbb2Hw4MFGf0ze7kZERGSC/Px8+Pj46F6rVCqLnt/b2xtHjhxBZWUlsrKykJqaig4dOmDgwIFGtWdiJyIiWbDUznM+Pj56ib05gYGBUCqVKCoq0isvKipCSEhIs+0UCgUiIyMBADExMTh58iTS0tKMTuwciiciInmw8ap4Nzc3xMbGIisrS1cmiiKysrIQHx9v9HlEUWx2Ht8Q9tiJiIisJDU1FUlJSejduzf69OmDZcuWoaqqCsnJyQCAcePGISwsTDdPn5aWht69e6Njx46ora3F1q1b8dFHH2HVqlVGX5OJnYiIZMEeD4EZPXo0iouLMWfOHBQWFiImJgaZmZm6BXUXLlyAQnFr8LyqqgqTJ0/GxYsX4e7uji5duuDjjz/G6NGjjb4mEzsREcmDnfaKT0lJQUpKisH3srOz9V4vXLgQCxcubNmFfsXETkREsiCXx7Zy8RwREZETYY+diIjkQSaPbWViJyIi2XCU4XRzcCieiIjIibDHTkRE8iBJjYc57R0AEzsREckCV8UTERGRw2GPnYiI5IGr4omIiJyHIDYe5rR3BByKJyIiciLssRMRkTxwKJ6IiMh5yGVVPBM7ERHJg0zuY+ccOxERkRNhj52IiGSBQ/FERETORCaL5zgUT0RE5ETYYyciIlngUDwREZEz4ap4IiIicjTssRMRkSxwKJ6IiMiZcFU8ERERORr22ImISBY4FE9ERORMRKnxMKe9A2BiJyIieeAcOxERETka9tiJiEgWBJg5x26xSKyLiZ2IiOSBO88RERGRo2GPnYiIZIG3uxERETkTroonIiIiR8MeOxERyYIgSRDMWABnTltbYmInIiJ5EH89zGnvADgUT0RE5ETYYyciIlngUDwREZEzkcmqeCZ2IiKSB+48R0RERI6GPXYiIpIF7jxHdvVo3HE82e8IAryq8UthAJZs6YufLwYbrDso6izGDzyMcP9yuChF5F/V4OM90fjfkU42jpqMMfLPP2P0sOPw11TjTL4f3vooHqfOtjJYd/jAHAzum4v2ba4BAE6fC8Dq//Zutv7z47/HiD/lYOUncfhi271W+wxkHM23xfDbWgRleT3qwt1x5alw1Hb0vGM7r/2laP2fc6jspUHB8x313nO9VI3Azy7D/dR1CFqgLkyNgqkd0BDoZq2P4TxkMhTPxH4XGtw9F88P24vFm/rjeH4QxvQ9hrfGf41H3hyDa1XuTeqXV6vwfnYvnCv2Rb1WgX6dz2POw9/hWqU79ueG2+ETUHMGxp3FpCcOYNna+3HyTCv8NfEEXn9xG5Je+ivKrjf9bqO7FGDH/g448UsQ6uqVGDP8GN54cRue/sdDKLmmnyD+GHsOUR2LUVLqYauPQ7fhtb8Ugesuonh8W9R09IDvtisIW5KL829EQevj2mw7l+JaBH56CdWdvZq851pUi/CFp1E+IAClD7WG6K6E26VqSG6O8kBRsgW7zrGnpaXhvvvug7e3N4KCgjBq1Cjk5OTYM6S7whN9f8LGH7ti86EuyCv2R9qm/qipd8GI2FMG6x/KC0P2z+1xrtgPl0o1WL+vB3KLAhATUWDjyOlOHh16HFuzOyNzdyecv+yHN9f2RW2tCx4YcNpg/UXpA/FVVlecuRCA/AJf/HN1XwgKCT2jLuvVC/SrwtSn9mNR+gA0aLl05m7gl3kFFQMDUdE/AHVh7rgyvi0klQI+O68230iUEJJ+DqUPt0Z9q6Y98IDPL6MqWoOrj7dBbYQH6oNVqOrle9sfCnSLIJp/OAK7/gXYuXMnpkyZgv3792P79u2or6/HkCFDUFVVZc+w7MpFqUWX0GIcyG2jK5MkAQdy26B72yIjziDhvg4X0S6wDIfyWlsvUDKZi1KLThFXcfBEqK5MkgQc/DkUUZHFRp1DpdLCRSniepVKVyYIEmb/bRcytnbHuUt+Fo+bWqBBhOrcDdy41/tWmULAjShvqHOb//vmv7EAWh8XVAwIbPqmKMHzaDnqQ1QIfeMXtJ/yE8JfPQXPg2WWj99Z3RyKN+dwAHYdis/MzNR7vXbtWgQFBeHgwYPo379/k/q1tbWora3Vva6oqLB6jLbm61EDF6WE0kr9YdnSSndEtCprtp2nqhZbZ34ENxcRWlHA65v74cAZDsPfTTTetVAqJVyr0P9ur5W7o23rMqPO8ezo/8PVax56Pw4eH/4TtFoBX34TZclwyQzK6w0QREDro/8ntkHjAo+CGoNt1DmV8Nl5FRcWdjV8zooGKGpE+G0pwtVHWqNkdBg8f6pA6+VncWn2Paju4m2wHcnPXTXHXl5eDgDw9/c3+H5aWhrmzZtny5Acxo06N4xd8Sg8VPW4r8MlTH9gLy6VeuNQXpi9QyMLGfOXoxgUdxapacNQX9/4T/eeiBL8dcjP+NuckQA4z+qohGotQt4+hytPt4Xo3cyf5V97i1W9NCgb2riQtq6dB9S5VdDsKGFiNwY3qLEtURTx/PPPo2/fvujWrZvBOrNnz0ZqaqrudUVFBcLDnatXWnZDjQatAH+var1yf69qXK1sflGUJAm4WKoBAJwuCERE0DWMH3CYif0uUn5dBa1WgJ+P/nfrp6lGafntF7w99sAxjBl+DDPeGIqz+bd++PboXARfn2qsfzNDV6ZUSvj7mAP465ATeOKFxyz7IcgoWm8XSIrGXvZvuZQ3oEHTdD7c9UotXEvqEPrmmVuFvyaRyPGHcP71e1Ef4ApJCdSGqfXa1oWq4X660uKfwRlxS1kbmzJlCo4fP449e/Y0W0elUkGlUjX7vjNo0Cpx6nIr3NfxEnaebA+gcQ71vo6X8N/9hn/wGKIQJLgptdYKk1qgQavE6XMB6HXvZXx/qB2Axu+2V9RlbPzW8PArAIwe9hPGjjiKmUsScTpPf+51+/cdcfB4qF7ZGy9uw/a9HZG5i7c72o2LArURHvA4cR1Vsb6NZaIE95+vozyh6a2K9a3VOL9I/7+BgM8vQ1EjovjJNqgPcAVcFKhp7wm3glq9em6FNWgI4K1udMtdsXw2JSUFW7ZswXfffYc2bdrcuYGTW/d9D4zqfRLDe+YgotU1zBqxC+5u9dh8sDMA4NVHdmDKkB909cf3P4Q+HfMR5leBiFbXMLbvUQyL+QX/O8o/7Heb/2Z2w/ABpzHkj7+gbWgZnk/aC7WqQZeEZz27ExMe/VFX//HhPyH5r4ew5L1+KCzxgp/mBvw0N6BW1QMAKirVOHfJT+9o0CpQWu6B/EKNXT4jNbo2NAg+O0vgvfsqXC9VI+iDfChqRVT0DwAABL99DgGfXQIASG4K1LVx1ztEDyVEdWM5XBr/VF8bFgzvH67B57sSuBbVQLP9CjwPl6Psz4b3NaDfsdPiuZUrVyIiIgJqtRpxcXE4cOBAs3Xfffdd9OvXD35+fvDz80NCQsJt6xti1x67JEmYOnUqNmzYgOzsbLRv396e4dw1th+LhK9nDf725/9DgPcNnC4IxHNrh6O0qnG4NkRzXe+/L7VbA2aO2I0gTRVq611wvtgXc/77J2w/FmmnT0DNyf6hA3y9a5D88CH4aapx5oI/Zi4ZoltQFxRQBVG6NVc+4k+n4OYqYt5zO/TO88GGGHywoZdNYyfTVP7BH8rrDQj4sqBxg5q27rj0YiS0vw7Fu1ytM3lZRFVvX1wZHw6/LUVo9XE+6ls3bk5TY+CedzJAgnnPVG9BXs/IyEBqairS09MRFxeHZcuWITExETk5OQgKCmpSPzs7G2PGjMH9998PtVqN119/HUOGDMGJEycQFmbc1KogSfabNJg8eTLWrVuHTZs2oXPnzrpyjUYDd/emm3X8XkVFBTQaDaKffA1KN/Ud65Nj886vs3cIZEPnxjnGfCaZR6yuQf6z81FeXg4fHx+rXONmrvhTz1lwUbY8VzRoa7Dj8GLk5+frxXq7aeK4uDjcd999WLFiBYDG9WTh4eGYOnUqZs2adcdrarVa+Pn5YcWKFRg3bpxRcdp1KH7VqlUoLy/HwIED0bp1a92RkZFx58ZERER2EB4eDo1GozvS0tIM1qurq8PBgweRkJCgK1MoFEhISMC+ffuMutaNGzdQX1/f7N1ihth9KJ6IiMgmJJi5V3zj/xjqsRtSUlICrVaL4GD953wEBwfj1CnDO4n+3syZMxEaGqr34+BO7ppV8URERFZloYfA+Pj4WG3a4LcWL16M9evXIzs7G2q18VMITOxERERWEBgYCKVSiaIi/e3Ai4qKEBISctu2//znP7F48WJ8++236NGjh0nXvStudyMiIrI60QKHCdzc3BAbG4usrKxbIYgisrKyEB8f32y7N954AwsWLEBmZiZ69+5t2kXBHjsREcmEPXaeS01NRVJSEnr37o0+ffpg2bJlqKqqQnJyMgBg3LhxCAsL0y3Ae/311zFnzhysW7cOERERKCwsBAB4eXnBy8u42xqZ2ImIiKxk9OjRKC4uxpw5c1BYWIiYmBhkZmbqFtRduHABCsWtwfNVq1ahrq4OjzzyiN555s6di1dffdWoazKxExGRPFho8ZypUlJSkJKSYvC97Oxsvdfnzp1r0TV+i4mdiIjkwU6J3da4eI6IiMiJsMdORETyIJMeOxM7ERHJgwiTH7zTpL0DYGInIiJZsMftbvbAOXYiIiInwh47ERHJA+fYiYiInIgoAYIZyVl0jMTOoXgiIiInwh47ERHJA4fiiYiInImZiR2Okdg5FE9ERORE2GMnIiJ54FA8ERGRExElmDWczlXxREREZGvssRMRkTxIYuNhTnsHwMRORETywDl2IiIiJ8I5diIiInI07LETEZE8cCieiIjIiUgwM7FbLBKr4lA8ERGRE2GPnYiI5IFD8URERE5EFAGYcS+66Bj3sXMonoiIyImwx05ERPLAoXgiIiInIpPEzqF4IiIiJ8IeOxERyYNMtpRlYiciIlmQJBGSGU9oM6etLTGxExGRPEiSeb1uzrETERGRrbHHTkRE8iCZOcfuID12JnYiIpIHUQQEM+bJHWSOnUPxREREToQ9diIikgcOxRMRETkPSRQhmTEU7yi3u3EonoiIyImwx05ERPLAoXgiIiInIkqA4PyJnUPxREREToQ9diIikgdJAmDOfeyO0WNnYiciIlmQRAmSGUPxEhM7ERHRXUQSYV6Pnbe7ERERkY2xx05ERLLAoXgiIiJnIpOheIdO7Dd/PWnrauwcCdlCQ0OdvUMgGxKrHaN3ROYRq2sB2KY33IB6s/anaUC95YKxIkFylLEFAy5evIjw8HB7h0FERGbKz89HmzZtrHLumpoatG/fHoWFhWafKyQkBHl5eVCr1RaIzDocOrGLoojLly/D29sbgiDYOxybqaioQHh4OPLz8+Hj42PvcMiK+F3Lh1y/a0mScP36dYSGhkKhsN567pqaGtTVmT/q5+bmdlcndcDBh+IVCoXVfuE5Ah8fH1n9AZAzftfyIcfvWqPRWP0aarX6rk/IlsLb3YiIiJwIEzsREZETYWJ3QCqVCnPnzoVKpbJ3KGRl/K7lg981WYpDL54jIiIifeyxExEROREmdiIiIifCxE5EROREmNiJiIicCBO7g1m5ciUiIiKgVqsRFxeHAwcO2DsksoJdu3bhwQcfRGhoKARBwMaNG+0dEllJWloa7rvvPnh7eyMoKAijRo1CTk6OvcMiB8bE7kAyMjKQmpqKuXPn4tChQ4iOjkZiYiKuXLli79DIwqqqqhAdHY2VK1faOxSysp07d2LKlCnYv38/tm/fjvr6egwZMgRVVVX2Do0cFG93cyBxcXG47777sGLFCgCNe+WHh4dj6tSpmDVrlp2jI2sRBAEbNmzAqFGj7B0K2UBxcTGCgoKwc+dO9O/f397hkANij91B1NXV4eDBg0hISNCVKRQKJCQkYN++fXaMjIgsqby8HADg7+9v50jIUTGxO4iSkhJotVoEBwfrlQcHB1vkUYREZH+iKOL5559H37590a1bN3uHQw7KoZ/uRkTkTKZMmYLjx49jz5499g6FHBgTu4MIDAyEUqlEUVGRXnlRURFCQkLsFBURWUpKSgq2bNmCXbt2yfpx1GQ+DsU7CDc3N8TGxiIrK0tXJooisrKyEB8fb8fIiMgckiQhJSUFGzZswI4dO9C+fXt7h0QOjj12B5KamoqkpCT07t0bffr0wbJly1BVVYXk5GR7h0YWVllZidzcXN3rvLw8HDlyBP7+/mjbtq0dIyNLmzJlCtatW4dNmzbB29tbt2ZGo9HA3d3dztGRI+Ltbg5mxYoVWLJkCQoLCxETE4Ply5cjLi7O3mGRhWVnZ2PQoEFNypOSkrB27VrbB0RWIwiCwfL3338f48ePt20w5BSY2ImIiJwI59iJiIicCBM7ERGRE2FiJyIiciJM7ERERE6EiZ2IiMiJMLETERE5ESZ2IiIiJ8LETkRE5ESY2InMNH78eIwaNUr3euDAgXj++edtHkd2djYEQUBZWVmzdQRBwMaNG40+56uvvoqYmBiz4jp37hwEQcCRI0fMOg8RGYeJnZzS+PHjIQgCBEGAm5sbIiMjMX/+fDQ0NFj92l9++SUWLFhgVF1jkjERkSn4EBhyWkOHDsX777+P2tpabN26FVOmTIGrqytmz57dpG5dXR3c3Nwscl1/f3+LnIeIqCXYYyenpVKpEBISgnbt2mHSpElISEjAV199BeDW8Plrr72G0NBQdO7cGQCQn5+Pxx57DL6+vvD398fIkSNx7tw53Tm1Wi1SU1Ph6+uLgIAAvPTSS/j94xZ+PxRfW1uLmTNnIjw8HCqVCpGRkVi9ejXOnTune9CLn58fBEHQPfRDFEWkpaWhffv2cHd3R3R0ND7//HO962zduhWdOnWCu7s7Bg0apBensWbOnIlOnTrBw8MDHTp0wCuvvIL6+vom9d5++22Eh4fDw8MDjz32GMrLy/Xef++999C1a1eo1Wp06dIF//nPf0yOhYgsg4mdZMPd3R11dXW611lZWcjJycH27duxZcsW1NfXIzExEd7e3ti9eze+//57eHl5YejQobp2//rXv7B27VqsWbMGe/bsQWlpKTZs2HDb644bNw6ffvopli9fjpMnT+Ltt9+Gl5cXwsPD8cUXXwAAcnJyUFBQgH//+98AgLS0NHz44YdIT0/HiRMnMH36dDz55JPYuXMngMYfIA8//DAefPBBHDlyBBMmTMCsWbNM/v/E29sba9euxc8//4x///vfePfdd/Hmm2/q1cnNzcVnn32GzZs3IzMzE4cPH8bkyZN173/yySeYM2cOXnvtNZw8eRKLFi3CK6+8gg8++MDkeIjIAiQiJ5SUlCSNHDlSkiRJEkVR2r59u6RSqaQZM2bo3g8ODpZqa2t1bT766COpc+fOkiiKurLa2lrJ3d1d2rZtmyRJktS6dWvpjTfe0L1fX18vtWnTRnctSZKkAQMGSNOmTZMkSZJycnIkANL27dsNxvndd99JAKRr167pympqaiQPDw9p7969enWfeeYZacyYMZIkSdLs2bOlqKgovfdnzpzZ5Fy/B0DasGFDs+8vWbJEio2N1b2eO3eupFQqpYsXL+rK/ve//0kKhUIqKCiQJEmSOnbsKK1bt07vPAsWLJDi4+MlSZKkvLw8CYB0+PDhZq9LRJbDOXZyWlu2bIGXlxfq6+shiiKeeOIJvPrqq7r3u3fvrjevfvToUeTm5sLb21vvPDU1NThz5gzKy8tRUFCAuLg43XsuLi7o3bt3k+H4m44cOQKlUokBAwYYHXdubi5u3LiBwYMH65XX1dWhZ8+eAICTJ0/qxQEA8fHxRl/jpoyMDCxfvhxnzpxBZWUlGhoa4OPjo1enbdu2CAsL07uOKIrIycmBt7c3zpw5g2eeeQYTJ07U1WloaIBGozE5HiIyHxM7Oa1BgwZh1apVcHNzQ2hoKFxc9P9z9/T01HtdWVmJ2NhYfPLJJ03O1apVqxbF4O7ubnKbyspKAMDXX3+tl1CBxnUDlrJv3z6MHTsW8+bNQ2JiIjQaDdavX49//etfJsf67rvvNvmhoVQqLRYrERmPiZ2clqenJyIjI42u36tXL2RkZCAoKKhJr/Wm1q1b44cffkD//v0BNPZMDx48iF69ehms3717d4iiiJ07dyIhIaHJ+zdHDLRara4sKioKKpUKFy5caLan37VrV91CwJv2799/5w/5G3v37kW7du3w8ssv68rOnz/fpN6FCxdw+fJlhIaG6q6jUCjQuXNnBAcHIzQ0FGfPnsXYsWNNuj4RWQcXzxH9auzYsQgMDMTIkSOxe/du5OXlITs7G8899xwuXrwIAJg2bRoWL16MjRs34tSpU5g8efJt70GPiIhAUlISnn76aWzcuFF3zs8++wwA0K5dOwiCgC1btqC4uBiVlZXw9vbGjBkzMH36dHzwwQc4c+YMDh06hLfeeku3IO3vf/87fvnlF7z44ovIycnBunXrsHbtWpM+7z333IMLFy5g/fr1OHPmDJYvX25wIaBarUZSUhKOHj2K3bt347nnnsNjjz2GkJAQAMC8efOQlpaG5cuX4/Tp0zh27Bjef/99LF261KR4iMgymNiJfuXh4YFdu3ahbdu2ePjhh9G1a1c888wzqKmp0fXgX3jhBTz11FNISkpCfHw8vL298dBDD932vKtWrcIjjzyCyZMno0uXLpg4cSKqqqoAAGFhYZg3bx5mzZqF4OBgpKSkAAAWLFiAV155BWlpaejatSuGDh2Kr7/+Gu3btwfQOO/9xRdfYOPGjYiOjkZ6ejoWLVpk0ucdMWIEpk+fjpSUFMTExGDv3r145ZVXmtSLjIzEww8/jGHDhmHIkCHo0aOH3u1sEyZMwHvvvYf3338f3bt3x4ABA7B27VpdrERkW4LU3KofIiIicjjssRMRETkRJnYiIiInwsRORETkRJjYiYiInAgTOxERkRNhYiciInIiTOxEREROhImdiIjIiTCxExEROREmdiIiIifCxE5ERORE/j8gbRVSmwljqQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.72      0.62       599\n",
      "           2       0.33      0.23      0.27       440\n",
      "           3       0.53      0.46      0.49       408\n",
      "\n",
      "    accuracy                           0.50      1447\n",
      "   macro avg       0.47      0.47      0.46      1447\n",
      "weighted avg       0.48      0.50      0.48      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#DistilBERT with no clearing the stopwords, square brackets, etc... + distilBERT cased\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "from keras.models import Model\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "MAX_LEN = 38\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 review  label\n",
      "0     @Jorge_LBU Espero que te mejores pronto, vomit...      0\n",
      "1     @ClubPaniniMx @PaniniComicsMx genial espero qu...      1\n",
      "2                     kali uchis va a estar en bahidorá      1\n",
      "3     @ferdiazgil @FranDguez sí, lo he leído ese tem...      0\n",
      "4     @AbrahamMateoESP Exacto! Todo lo que él hace l...      1\n",
      "...                                                 ...    ...\n",
      "4335               tu en serio por que sois tan tontos       0\n",
      "4336  Yo muchísimo mas . Hablamos al DM y te paso él...      1\n",
      "4337  Les platicó algo bonito? Bueno pues, el último...      2\n",
      "4338           Una breve reseña de quien soy realmente.      1\n",
      "4339                   @MicaGiudice el tuyo quedo mejor      2\n",
      "\n",
      "[4340 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 391kB/s] \n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 7.66kB/s]\n",
      "Downloading: 100%|██████████| 411/411 [00:00<00:00, 146kB/s]\n",
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 38\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True,)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.64      0.63       599\n",
      "           2       0.41      0.41      0.41       440\n",
      "           3       0.59      0.57      0.58       408\n",
      "\n",
      "    accuracy                           0.55      1447\n",
      "   macro avg       0.54      0.54      0.54      1447\n",
      "weighted avg       0.55      0.55      0.55      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#DistilBERT with diferent learning rate (lr=5e-6)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "from keras.models import Model\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "MAX_LEN = 38\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Environment stopwords for train\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_train['review']=df_train['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment stopwords for dev\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_dev['review']=df_dev['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 38\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True,)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-6, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.66      0.61       599\n",
      "           2       0.37      0.26      0.30       440\n",
      "           3       0.52      0.54      0.53       408\n",
      "\n",
      "    accuracy                           0.51      1447\n",
      "   macro avg       0.48      0.49      0.48      1447\n",
      "weighted avg       0.49      0.51      0.49      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    precision    recall  f1-score   support\n",
    "\n",
    "distilBERT (dataclearing and lr=5e-5)\n",
    "\n",
    "1       0.60      0.57      0.58       599\n",
    "2       0.38      0.44      0.41       440\n",
    "3       0.61      0.55      0.57       408\n",
    "\n",
    "distilBERT (no dataclearing and lr=5e-5)\n",
    "\n",
    "1       0.62      0.64      0.63       599\n",
    "2       0.41      0.41      0.41       440\n",
    "3       0.59      0.57      0.58       408\n",
    "\n",
    "distilBERT (dataclearing and lr=5e-6)\n",
    "\n",
    "1       0.56      0.66      0.61       599\n",
    "2       0.37      0.26      0.30       440\n",
    "3       0.52      0.54      0.53       408\n",
    "\n",
    "distilBERT (newdataclearing and lr=5e-5)\n",
    "\n",
    "1       0.55      0.72      0.62       599\n",
    "2       0.33      0.23      0.27       440\n",
    "3       0.53      0.46      0.49       408"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
