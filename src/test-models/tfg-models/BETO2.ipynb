{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-06 19:35:47.376927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4340, 2)\n",
      "(1447, 2)\n"
     ]
    }
   ],
   "source": [
    "#Modelo BETO\n",
    "#Libreria transformers (modelo BERT predefinido para la clasificación (BertForSequenceClassification))\n",
    "#Libreria sera BERT + Capa de clasificación por encima\n",
    "#Debemos tokenizar nuestro dataset (tokens + attention mask + max_length)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "MAX_LEN = 32\n",
    "\n",
    "# Select cpu or cuda\n",
    "run_on = 'cpu'\n",
    "device = torch.device(run_on)\n",
    "\n",
    "df_train = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.isnull().sum()\n",
    "df_train.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_train.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_train.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_train.head()\n",
    "df_train['review'] = df_train['text']\n",
    "df_train.drop('text', axis=1, inplace=True)\n",
    "df_train['label'] = df_train['sentiment']\n",
    "df_train.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_dev = pd.read_csv('/Users/nfanlo/dev/spanish-classifier-tfg/dataset/60-20-20/dev.csv')\n",
    "print(df_dev.shape)\n",
    "df_dev.isnull().sum()\n",
    "df_dev.sentiment.replace(\"P\" , 2 , inplace = True)\n",
    "df_dev.sentiment.replace(\"N\" , 0 , inplace = True)\n",
    "df_dev.sentiment.replace(\"NEU\" , 1, inplace = True)\n",
    "df_dev['review'] = df_dev['text']\n",
    "df_dev.drop('text', axis=1, inplace=True)\n",
    "df_dev['label'] = df_dev['sentiment']\n",
    "df_dev.drop('sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Environment stopwords for train\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_train['review']=df_train['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment stopwords for dev\n",
    "stop = set(stopwords.words('spanish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Data cleaning stopwords (ignored)\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df_dev['review']=df_dev['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 0]\n",
    "y_train = df_train.iloc[:, 1]\n",
    "X_dev = df_dev.iloc[:, 0]\n",
    "y_dev = df_dev.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max n°tokens in a sentence: 32\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased',\n",
    "            do_lower_case=True)\n",
    "\n",
    "def preprocessing(dataset):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for doc in dataset:\n",
    "        encoded_doc = tokenizer.encode_plus(doc,\n",
    "                   add_special_tokens=True, max_length=MAX_LEN,\n",
    "                   truncation=True ,pad_to_max_length=True,\n",
    "                   return_token_type_ids = False,\n",
    "                   return_attention_mask = True)\n",
    "        input_ids.append(encoded_doc['input_ids'])\n",
    "        attention_mask.append(encoded_doc['attention_mask'])\n",
    "    return (torch.tensor(input_ids),\n",
    "           torch.tensor(attention_mask))\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "X_train_inputs, X_train_masks = preprocessing(X_train)\n",
    "X_dev_inputs, X_dev_masks = preprocessing(X_dev)\n",
    "\n",
    "# Report max n° tokens in a sentence\n",
    "max_len = max([torch.sum(sen) for sen in X_train_masks])\n",
    "print('Max n°tokens in a sentence: {0}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "batch_size = 8\n",
    "\n",
    "y_train_labels = torch.tensor(y_train.values)\n",
    "y_dev_labels = torch.tensor(y_dev.values)\n",
    "\n",
    "def dataloader(x_inputs, x_masks, y_labels):\n",
    "    data = TensorDataset(x_inputs, x_masks, y_labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = dataloader(X_train_inputs, X_train_masks, y_train_labels)\n",
    "val_dataloader = dataloader(X_dev_inputs, X_dev_masks, y_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/nfanlo/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo + optimizador + definimos EPOCHS + Scheduler\n",
    "#Modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-cased', num_labels=3,\n",
    " output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-6)\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps= total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para formatear el tiempo y otra para calcular la exactitud\n",
    "#fuction to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "#function to compute accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 4 =======\n",
      "======= Epoch 2 / 4 =======\n",
      "======= Epoch 3 / 4 =======\n",
      "======= Epoch 4 / 4 =======\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.64      0.66       599\n",
      "           2       0.45      0.49      0.47       440\n",
      "           3       0.64      0.63      0.63       408\n",
      "\n",
      "    accuracy                           0.59      1447\n",
      "   macro avg       0.59      0.59      0.59      1447\n",
      "weighted avg       0.60      0.59      0.59      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definimos la funcion para entrenar el modelo y entregar los resultados en el set de validación\n",
    "#Train model\n",
    "def training(n_epochs, training_dataloader, validation_dataloader):\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
    "        # Mira cuanto tiempo le cuesta entrenar un EPOCH.\n",
    "        t0 = time.time()\n",
    "        # Resetea la perdida para este EPOCH.\n",
    "        total_loss = 0\n",
    "        # Pone el modelo en modo entrenamiento.\n",
    "        model.train()\n",
    "        # Para cada batch en el training data\n",
    "        for step, batch in enumerate(training_dataloader):\n",
    "            batch_loss = 0\n",
    "            # Unpack this training batch from dataloader\n",
    "            #   [0]: input ids, [1]: attention masks, \n",
    "            #   [2]: labels\n",
    "            b_input_ids,b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "            # Limpia el gradiente calculado anteriormente\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Genera un paso adelante\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # Saca el loss value fuera del output\n",
    "            loss = outputs[0]\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Genera un paso atras\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipea el los gradientes a 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                            1.0)\n",
    "\n",
    "            # Actualiza los parametros\n",
    "            # ¿take a step using the computed gradient?\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calcula el average loss sobre el training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        #Validación\n",
    "        # Despues de completar un entrenamiento genera un paso de validacion\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Pone el modelo en modo evaluación\n",
    "        model.eval()\n",
    "\n",
    "        # Trackea las variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        # Evalua el data para un epoch mas\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            # Add batch to device\n",
    "            # Unpack this training batch from our dataloader.\n",
    "            #   [0]: input ids, [1]: attention masks,\n",
    "            #   [2]: labels\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(\n",
    "                                t.to(device) for t in batch)\n",
    "\n",
    "\n",
    "            # El modelo no computa los gradientes\n",
    "            with torch.no_grad():\n",
    "                # Paso adelante \n",
    "                # Devolvemos los loggits \n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # Los \"logits\" son el valor de salida\n",
    "            # Prioriza aplicar la funcion de activación\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Mueve los logits y labels a la CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Guarda los logits y labels del batch\n",
    "            # Utilizamos esto en la matriz de confusión\n",
    "            predict_labels = np.argmax(logits, axis=1).flatten()\n",
    "            all_logits.extend(predict_labels.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "            # Calcula la precision para este batch\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, b_labels)\n",
    "            # Accumula la precisión total\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #Print la matriz de confussión\"\n",
    "    conf = confusion_matrix(all_labels, all_logits, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    target_names = ['1', '2', '3']\n",
    "    print(classification_report(all_labels, all_logits, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Llamamos a la funcion para entrenar el modelo\n",
    "training(epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
